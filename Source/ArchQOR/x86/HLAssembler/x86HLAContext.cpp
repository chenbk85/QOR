//x86HLAContext.cpp

// Copyright (c) 2008-2010, Petr Kobalicek <kobalicek.petr@gmail.com>
// Copyright (c) Querysoft Limited 2012, 2015
//
// Permission is hereby granted, free of charge, to any person or organization
// obtaining a copy of the software and accompanying documentation covered by
// this license (the "Software") to use, reproduce, display, distribute,
// execute, and transmit the Software, and to prepare derivative works of the
// Software, and to permit third-parties to whom the Software is furnished to
// do so, all subject to the following:
// 
// The copyright notices in the Software and this entire statement, including
// the above license grant, this restriction and the following disclaimer,
// must be included in all copies of the Software, in whole or in part, and
// all derivative works of the Software, unless such copies or derivative
// works are solely in the form of machine-executable object code generated by
// a source language processor.
// 
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
// FITNESS FOR A PARTICULAR PURPOSE, TITLE AND NON-INFRINGEMENT. IN NO EVENT
// SHALL THE COPYRIGHT HOLDERS OR ANYONE DISTRIBUTING THE SOFTWARE BE LIABLE
// FOR ANY DAMAGES OR OTHER LIABILITY, WHETHER IN CONTRACT, TORT OR OTHERWISE,
// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
// DEALINGS IN THE SOFTWARE.

//Implement core state management for x86 high level assembler

#include "ArchQOR.h"

#if		( QOR_ARCH == QOR_ARCH_X86_32 || QOR_ARCH == QOR_ARCH_X86_64 )

#include "ArchQOR/x86/HLAssembler/x86HLAContext.h"
#include "ArchQOR/x86/HLAssembler/Emittables/EFunction.h"
#include "ArchQOR/x86/HLAssembler/Emittables/ECall.h"
#include "ArchQOR/Common/HLAssembler/Emittables/EComment.h"
#include <assert.h>
#include <new>

//------------------------------------------------------------------------------
namespace nsArch
{
	//------------------------------------------------------------------------------
	namespace nsx86
	{
		//------------------------------------------------------------------------------
		Cx86HLAContext::Cx86HLAContext( nsArch::CHighLevelAssemblerBase* pHLA ) __QCMP_THROW :
		m_Zone( 8192 - sizeof( CZone::Chunk ) - 32 )
		{
			m_pHLA = pHLA;
			m_pCPU = 0;
			_clear();

			m_bEmitComments = m_pHLA->getLogger() != 0;
		}

		//------------------------------------------------------------------------------
		Cx86HLAContext::~Cx86HLAContext() __QCMP_THROW
		{
		}

		//------------------------------------------------------------------------------
		void Cx86HLAContext::_clear() __QCMP_THROW
		{
			m_Zone.clear();
			m_pFunction = 0;
			m_pStart = 0;
			m_pStop = 0;
			m_pState.clear();
			m_pActive = 0;
			m_pForwardJumps = 0;
			m_uiCurrentOffset = 0;
			m_uiUnreachable = 0;
			m_uiModifiedGPRegisters = 0;
			m_uiModifiedMMRegisters = 0;
			m_uiModifiedXMMRegisters = 0;
			m_uiAllocableEBP = false;
			m_iAdjustESP = 0;
			m_uiArgumentsBaseReg = static_cast< Cmp_unsigned__int32 >( INVALID_VALUE ); // Used by patcher.
			m_iArgumentsBaseOffset = 0;          // Used by patcher.
			m_iArgumentsActualDisp = 0;          // Used by translate().
			m_uiVariablesBaseReg = static_cast< Cmp_unsigned__int32 >( INVALID_VALUE ); // Used by patcher.
			m_iVariablesBaseOffset = 0;          // Used by patcher.
			m_iVariablesActualDisp = 0;          // Used by translate()
			m_pMemUsed = 0;
			m_pMemFree = 0;
			m_uiMem4BlocksCount = 0;
			m_uiMem8BlocksCount = 0;
			m_uiMem16BlocksCount = 0;
			m_uiMemBytesTotal = 0;
			m_VecBackCode.clear();
			m_uiBackPos = 0;
			m_pCPU = 0;
		}

		//------------------------------------------------------------------------------
		void Cx86HLAContext::allocVar( VarData* vdata, Cmp_unsigned__int32 regMask, Cmp_unsigned__int32 vflags ) __QCMP_THROW
		{
			switch( vdata->type )
			{
			case VARIABLE_TYPE_GPD:
#if ( QOR_ARCH_WORDSIZE == 64 )
			case VARIABLE_TYPE_GPQ:
#endif //
				allocGPVar( vdata, regMask, vflags );
				break;

			case VARIABLE_TYPE_X87:
			case VARIABLE_TYPE_X87_1F:
			case VARIABLE_TYPE_X87_1D:
				// TODO: X87 VARIABLES NOT IMPLEMENTED.
				break;

			case VARIABLE_TYPE_MM:
				allocMMVar( vdata, regMask, vflags );
				break;

			case VARIABLE_TYPE_XMM:
			case VARIABLE_TYPE_XMM_1F:
			case VARIABLE_TYPE_XMM_4F:
			case VARIABLE_TYPE_XMM_1D:
			case VARIABLE_TYPE_XMM_2D:
				allocXMMVar( vdata, regMask, vflags );
				break;
			}

			_postAlloc( vdata, vflags );
		}

		//------------------------------------------------------------------------------
		void Cx86HLAContext::saveVar( VarData* vdata ) __QCMP_THROW
		{
			switch( vdata->type )
			{
			case VARIABLE_TYPE_GPD:
#if ( QOR_ARCH_WORDSIZE == 64 )
			case VARIABLE_TYPE_GPQ:
#endif // ASMJIT_X64
				saveGPVar( vdata );
				break;

			case VARIABLE_TYPE_X87:
			case VARIABLE_TYPE_X87_1F:
			case VARIABLE_TYPE_X87_1D:
				// TODO: X87 VARIABLES NOT IMPLEMENTED.
				break;

			case VARIABLE_TYPE_MM:
				saveMMVar( vdata );
				break;

			case VARIABLE_TYPE_XMM:
			case VARIABLE_TYPE_XMM_1F:
			case VARIABLE_TYPE_XMM_4F:
			case VARIABLE_TYPE_XMM_1D:
			case VARIABLE_TYPE_XMM_2D:
				saveXMMVar( vdata );
				break;
			}
		}

		//------------------------------------------------------------------------------
		void Cx86HLAContext::spillVar( VarData* vdata ) __QCMP_THROW
		{
			switch( vdata->type )
			{
			case VARIABLE_TYPE_GPD:
#if ( QOR_ARCH_WORDSIZE == 64 )
			case VARIABLE_TYPE_GPQ:
#endif // ASMJIT_X64
				spillGPVar( vdata );
				break;

			case VARIABLE_TYPE_X87:
			case VARIABLE_TYPE_X87_1F:
			case VARIABLE_TYPE_X87_1D:
				// TODO: X87 VARIABLES NOT IMPLEMENTED.
				break;

			case VARIABLE_TYPE_MM:
				spillMMVar( vdata );
				break;

			case VARIABLE_TYPE_XMM:
			case VARIABLE_TYPE_XMM_1F:
			case VARIABLE_TYPE_XMM_4F:
			case VARIABLE_TYPE_XMM_1D:
			case VARIABLE_TYPE_XMM_2D:
				spillXMMVar( vdata );
				break;
			}
		}

		//------------------------------------------------------------------------------
		void Cx86HLAContext::unuseVar( VarData* vdata, Cmp_unsigned__int32 toState ) __QCMP_THROW
		{
			assert( toState != VARIABLE_STATE_REGISTER );

			if( vdata->state == VARIABLE_STATE_REGISTER )
			{
				Cmp_unsigned__int32 registerIndex = vdata->registerIndex;
				switch( vdata->type )
				{
				case VARIABLE_TYPE_GPD:
#if ( QOR_ARCH_WORDSIZE == 64 )
				case VARIABLE_TYPE_GPQ:
#endif // ASMJIT_X64
					m_pState.gp[ registerIndex ] = 0;
					_freedGPRegister( registerIndex );
					break;

				case VARIABLE_TYPE_X87:
				case VARIABLE_TYPE_X87_1F:
				case VARIABLE_TYPE_X87_1D:
					// TODO: X87 VARIABLES NOT IMPLEMENTED.
					break;

				case VARIABLE_TYPE_MM:
					m_pState.mm[ registerIndex ] = 0;
					_freedMMRegister( registerIndex );
					break;

				case VARIABLE_TYPE_XMM:
				case VARIABLE_TYPE_XMM_1F:
				case VARIABLE_TYPE_XMM_4F:
				case VARIABLE_TYPE_XMM_1D:
				case VARIABLE_TYPE_XMM_2D:
					m_pState.xmm[ registerIndex ] = 0;
					_freedXMMRegister( registerIndex );
					break;
				}
			}

			vdata->state = static_cast< Cmp_unsigned__int8 >( toState );
			vdata->changed = false;
			vdata->registerIndex = static_cast< Cmp_unsigned__int32 >( INVALID_VALUE );
		}

		//------------------------------------------------------------------------------
		void Cx86HLAContext::allocGPVar( VarData* vdata, Cmp_unsigned__int32 regMask, Cmp_unsigned__int32 vflags ) __QCMP_THROW
		{
			// Fix the regMask (0 or full bit-array means that any register may be used).
			if( regMask == 0 )
			{
				regMask = nsCodeQOR::maskUpToIndex( REG_NUM_GP );
			}

			regMask &= nsCodeQOR::maskUpToIndex( REG_NUM_GP );

			// Working variables.
			Cmp_unsigned__int32 i;
			Cmp_unsigned__int32 mask;
			Cmp_unsigned__int32 home = vdata->homeRegisterIndex;									// Last register code (aka home).			
			Cmp_unsigned__int32 idx = static_cast< Cmp_unsigned__int32 >( INVALID_VALUE );			// New register code.
			Cmp_unsigned__int32 preservedGP = vdata->scope->getPrototype().getPreservedGP();		// Preserved GP variables.			
			VarData* spillCandidate = 0;															// Spill candidate.
			bool nonPreservedFirst = true;															// Whether to alloc the non-preserved variables first.

			if( getFunction()->isCaller() )
			{
				nonPreservedFirst = vdata->firstCallable == 0 || vdata->firstCallable->getOffset() >= vdata->lastEmittable->getOffset();
			}

			//Already Allocated

			// Go away if variable is already allocated.
			if( vdata->state == VARIABLE_STATE_REGISTER )
			{
				Cmp_unsigned__int32 oldIndex = vdata->registerIndex;

				// Already allocated in the right register.
				if( nsCodeQOR::maskFromIndex( oldIndex ) & regMask )
				{
					return;
				}

				// Try to find unallocated register first.
				mask = regMask & ~m_pState.usedGP;
				if (mask != 0)
				{
					idx = nsCodeQOR::findFirstBit( ( nonPreservedFirst && ( mask & ~preservedGP ) != 0 ) ? mask & ~preservedGP : mask );
				}
				// Then find the allocated and later exchange.
				else
				{
					idx = nsCodeQOR::findFirstBit( regMask & m_pState.usedGP );
				}
				assert( idx != INVALID_VALUE );

				VarData* other = m_pState.gp[ idx ];
				emitExchangeVar( vdata, idx, vflags, other );

				m_pState.gp[ oldIndex ] = other;
				m_pState.gp[ idx      ] = vdata;

				if( other )
				{
					other->registerIndex = oldIndex;
				}
				else
				{
					_freedGPRegister( oldIndex );
				}

				// Update VarData.
				vdata->state = VARIABLE_STATE_REGISTER;
				vdata->registerIndex = idx;
				vdata->homeRegisterIndex = idx;

				_allocatedGPRegister( idx );
				return;
			}

			// Find Unused GP
			// If regMask contains restricted registers which may be used then everything is handled in this block.
			if( regMask != nsCodeQOR::maskUpToIndex( REG_NUM_GP ) )
			{
				// Try to find unallocated register first.
				mask = regMask & ~m_pState.usedGP;
				if( mask != 0 )
				{
					idx = nsCodeQOR::findFirstBit( ( nonPreservedFirst && ( mask & ~preservedGP ) != 0 ) ? ( mask & ~preservedGP ) : mask );
					assert( idx != INVALID_VALUE );
				}
				// Then find the allocated and later spill.
				else
				{
					idx = nsCodeQOR::findFirstBit( regMask & m_pState.usedGP );
					assert( idx != INVALID_VALUE );					
					spillCandidate = m_pState.gp[ idx ];		// Spill register we need.					
					goto L_Spill;								// Jump to spill part of allocation.
				}
			}

			// Home register code.
			if( idx == INVALID_VALUE && home != INVALID_VALUE )
			{
				if( ( m_pState.usedGP & ( 1U << home ) ) == 0 ) 
				{
					idx = home;
				}
			}

			// We start from 1, because EAX/RAX register is sometimes explicitly
			// needed. So we trying to prevent reallocation in near future.
			if( idx == INVALID_VALUE )
			{
				for( i = 1, mask = ( 1 << i ); i < REG_NUM_GP; i++, mask <<= 1 )
				{
					if( ( m_pState.usedGP & mask ) == 0 && ( i != REG_INDEX_EBP || m_uiAllocableEBP ) && ( i != REG_INDEX_ESP ) )
					{
						// Convenience to alloc non-preserved first or non-preserved last.
						if( nonPreservedFirst )
						{ 
							if( idx != INVALID_VALUE && ( preservedGP & mask ) != 0 )
							{
								continue;
							}
							idx = i;
							// If current register is preserved, we should try to find different
							// one that is not. This can save one push / pop in prolog / epilog.
							if( ( preservedGP & mask ) == 0 )
							{
								break;
							}
						}
						else
						{
							if( idx != INVALID_VALUE && ( preservedGP & mask ) == 0 )
							{
								continue;
							}
							idx = i;
							// The opposite.
							if( ( preservedGP & mask ) != 0 )
							{
								break;
							}
						}
					}
				}
			}

			// If not found, try EAX/RAX.
			if( idx == INVALID_VALUE && ( m_pState.usedGP & 1 ) == 0 )
			{
				idx = REG_INDEX_EAX;
			}

			// Spill

			// If register is still not found, spill other variable.
			if( idx == INVALID_VALUE )
			{
				if( spillCandidate == 0 )
				{
					spillCandidate = _getSpillCandidateGP();
				}

				// Spill candidate not found?
				if( spillCandidate == 0 )
				{
					( dynamic_cast< Cx86HLAssembler* >(m_pHLA) )->setError( ERROR_NOT_ENOUGH_REGISTERS );
					return;
				}

	L_Spill:

				// Prevented variables can't be spilled. _getSpillCandidate() never returns prevented variables, but when jumping to L_spill it can happen.
				if( spillCandidate->workOffset == m_uiCurrentOffset )
				{
					( dynamic_cast< Cx86HLAssembler* >( m_pHLA ) )->setError( ERROR_REGISTERS_OVERLAP );
					return;
				}

				idx = spillCandidate->registerIndex;
				spillGPVar( spillCandidate );
			}

			// Alloc

			if( vdata->state == VARIABLE_STATE_MEMORY && ( vflags & VARIABLE_ALLOC_READ ) != 0 )
			{
				emitLoadVar( vdata, idx );
			}

			// Update VarData.
			vdata->state = VARIABLE_STATE_REGISTER;
			vdata->registerIndex = idx;
			vdata->homeRegisterIndex = idx;

			// Update StateData.
			_allocatedVariable( vdata );
		}

		//------------------------------------------------------------------------------
		void Cx86HLAContext::saveGPVar( VarData* vdata ) __QCMP_THROW
		{
			// Can't save variable that isn't allocated.
			assert( vdata->state == VARIABLE_STATE_REGISTER );
			assert( vdata->registerIndex != INVALID_VALUE );

			Cmp_unsigned__int32 idx = vdata->registerIndex;
			emitSaveVar( vdata, idx );

			// Update VarData.
			vdata->changed = false;
		}

		//------------------------------------------------------------------------------
		void Cx86HLAContext::spillGPVar( VarData* vdata ) __QCMP_THROW
		{
			// Can't spill variable that isn't allocated.
			assert( vdata->state == VARIABLE_STATE_REGISTER );
			assert( vdata->registerIndex != INVALID_VALUE );

			Cmp_unsigned__int32 idx = vdata->registerIndex;

			if( vdata->changed ) 
			{
				emitSaveVar( vdata, idx );
			}

			// Update VarData.
			vdata->registerIndex = static_cast< Cmp_unsigned__int32 >( INVALID_VALUE );
			vdata->state = VARIABLE_STATE_MEMORY;
			vdata->changed = false;

			// Update StateData.
			m_pState.gp[ idx ] = 0;
			_freedGPRegister( idx );
		}

		//------------------------------------------------------------------------------
		void Cx86HLAContext::allocMMVar( VarData* vdata, Cmp_unsigned__int32 regMask, Cmp_unsigned__int32 vflags ) __QCMP_THROW
		{
			// Fix the regMask ( 0 or full bit-array means that any register may be used ).
			if( regMask == 0 )
			{
				regMask = nsCodeQOR::maskUpToIndex( REG_NUM_MM );
			}
			regMask &= nsCodeQOR::maskUpToIndex( REG_NUM_MM );

			// Working variables.
			Cmp_unsigned__int32 i;
			Cmp_unsigned__int32 mask;

			// Last register code (aka home).
			Cmp_unsigned__int32 home = vdata->homeRegisterIndex;
			// New register code.
			Cmp_unsigned__int32 idx = static_cast< Cmp_unsigned__int32 >( INVALID_VALUE );

			// Preserved MM variables.
			//
			// NOTE: Currently MM variables are not preserved and there is no calling
			// convention known to me that does that. But on the other side it's possible
			// to write such calling convention.
			Cmp_unsigned__int32 preservedMM = vdata->scope->getPrototype().getPreservedMM();
			VarData* spillCandidate = 0;							// Spill candidate.
			bool nonPreservedFirst = true;							// Whether to alloc non-preserved first or last.

			if( this->getFunction()->isCaller() )
			{
				nonPreservedFirst = vdata->firstCallable == 0 || vdata->firstCallable->getOffset() >= vdata->lastEmittable->getOffset();
			}

			// Already Allocated

			// Go away if variable is already allocated.
			if( vdata->state == VARIABLE_STATE_REGISTER )
			{
				Cmp_unsigned__int32 oldIndex = vdata->registerIndex;

				// Already allocated in the right register.
				if( nsCodeQOR::maskFromIndex( oldIndex ) & regMask )
				{
					return;
				}

				// Try to find unallocated register first.
				mask = regMask & ~m_pState.usedMM;
				if( mask != 0 )
				{
					idx = nsCodeQOR::findFirstBit( ( nonPreservedFirst && ( mask & ~preservedMM ) != 0 ) ? mask & ~preservedMM : mask );
				}				
				else	// Then find the allocated and later exchange.
				{
					idx = nsCodeQOR::findFirstBit( regMask & m_pState.usedMM );
				}

				assert( idx != INVALID_VALUE );

				VarData* other = m_pState.mm[ idx ];
				if( other )
				{
					spillMMVar( other );
				}

				emitMoveVar( vdata, idx, vflags );
				_freedMMRegister( oldIndex );
				m_pState.mm[ idx ] = vdata;

				// Update VarData.
				vdata->state = VARIABLE_STATE_REGISTER;
				vdata->registerIndex = idx;
				vdata->homeRegisterIndex = idx;

				_allocatedMMRegister( idx );
				return;
			}

			// Find Unused MM

			// If regMask contains restricted registers which may be used then everything is handled in this block.
			if( regMask != nsCodeQOR::maskUpToIndex( REG_NUM_MM ) )
			{
				// Try to find unallocated register first.
				mask = regMask & ~m_pState.usedMM;
				if( mask != 0 )
				{
					idx = nsCodeQOR::findFirstBit( (nonPreservedFirst && ( mask & ~preservedMM ) != 0 ) ? mask & ~preservedMM : mask );
					assert( idx != INVALID_VALUE );
				}				
				else		// Then find the allocated and later spill.
				{
					idx = nsCodeQOR::findFirstBit( regMask & m_pState.usedMM );
					assert( idx != INVALID_VALUE );					
					spillCandidate = m_pState.mm[ idx ];		// Spill register we need.
					goto L_Spill;								// Jump to spill part of allocation.
				}
			}

			// Home register code.
			if( idx == INVALID_VALUE && home != INVALID_VALUE )
			{
				if( ( m_pState.usedMM & ( 1U << home ) ) == 0 )
				{
					idx = home;
				}
			}

			if( idx == INVALID_VALUE )
			{
				for( i = 0, mask = ( 1 << i ); i < REG_NUM_MM; i++, mask <<= 1 )
				{
					if( ( m_pState.usedMM & mask ) == 0 )
					{
						// Convenience to alloc non-preserved first or non-preserved last.
						if( nonPreservedFirst )
						{
							if( idx != INVALID_VALUE && ( preservedMM & mask ) != 0 )
							{
								continue;
							}
							idx = i;
							// If current register is preserved, we should try to find different
							// one that is not. This can save one push / pop in prolog / epilog.
							if( ( preservedMM & mask ) == 0 )
							{
								break;
							}
						}
						else
						{
							if( idx != INVALID_VALUE && ( preservedMM & mask ) == 0 )
							{
								continue;
							}
							idx = i;
							// The opposite.
							if( ( preservedMM & mask ) != 0 )
							{
								break;
							}
						}
					}
				}
			}

			// Spill

			// If register is still not found, spill other variable.
			if( idx == INVALID_VALUE )
			{
				if( spillCandidate == 0 )
				{
					spillCandidate = _getSpillCandidateMM();
				}

				// Spill candidate not found?
				if( spillCandidate == 0 )
				{
					( dynamic_cast< Cx86HLAssembler* >(m_pHLA) )->setError( ERROR_NOT_ENOUGH_REGISTERS );
					return;
				}

		L_Spill:

				// Prevented variables can't be spilled. _getSpillCandidate() never returns
				// prevented variables, but when jumping to L_spill it can happen.
				if( spillCandidate->workOffset == m_uiCurrentOffset )
				{
					( dynamic_cast< Cx86HLAssembler* >(m_pHLA) )->setError( ERROR_REGISTERS_OVERLAP );
					return;
				}

				idx = spillCandidate->registerIndex;
				spillMMVar( spillCandidate );
			}

			// Alloc

			if( vdata->state == VARIABLE_STATE_MEMORY && ( vflags & VARIABLE_ALLOC_READ ) != 0 )
			{
				emitLoadVar( vdata, idx );
			}

			// Update VarData.
			vdata->state = VARIABLE_STATE_REGISTER;
			vdata->registerIndex = idx;
			vdata->homeRegisterIndex = idx;

			// Update StateData.
			_allocatedVariable( vdata );
		}

		//------------------------------------------------------------------------------
		void Cx86HLAContext::saveMMVar( VarData* vdata ) __QCMP_THROW
		{
			// Can't save variable that isn't allocated.
			assert( vdata->state == VARIABLE_STATE_REGISTER );
			assert( vdata->registerIndex != INVALID_VALUE );

			Cmp_unsigned__int32 idx = vdata->registerIndex;
			emitSaveVar( vdata, idx );

			// Update VarData.
			vdata->changed = false;
		}

		//------------------------------------------------------------------------------
		void Cx86HLAContext::spillMMVar( VarData* vdata ) __QCMP_THROW
		{
			// Can't spill variable that isn't allocated.
			assert( vdata->state == VARIABLE_STATE_REGISTER );
			assert( vdata->registerIndex != INVALID_VALUE );

			Cmp_unsigned__int32 idx = vdata->registerIndex;

			if( vdata->changed ) 
			{
				emitSaveVar( vdata, idx );
			}

			// Update VarData.
			vdata->registerIndex = static_cast< Cmp_unsigned__int32 >( INVALID_VALUE );
			vdata->state = VARIABLE_STATE_MEMORY;
			vdata->changed = false;

			// Update StateData.
			m_pState.mm[ idx ] = 0;
			_freedMMRegister( idx );
		}

		//------------------------------------------------------------------------------
		void Cx86HLAContext::allocXMMVar( VarData* vdata, Cmp_unsigned__int32 regMask, Cmp_unsigned__int32 vflags ) __QCMP_THROW
		{
			// Fix the regMask (0 or full bit-array means that any register may be used).
			if( regMask == 0 ) 
			{
				regMask = nsCodeQOR::maskUpToIndex( REG_NUM_XMM );
			}
			regMask &= nsCodeQOR::maskUpToIndex( REG_NUM_XMM );

			// Working variables.
			Cmp_unsigned__int32 i;
			Cmp_unsigned__int32 mask;
			
			Cmp_unsigned__int32 home = vdata->homeRegisterIndex;									// Last register code (aka home).
			Cmp_unsigned__int32 idx = static_cast< Cmp_unsigned__int32 >( INVALID_VALUE );			// New register code.			
			Cmp_unsigned__int32 preservedXMM = vdata->scope->getPrototype().getPreservedXMM();		// Preserved XMM variables.			
			VarData* spillCandidate = 0;															// Spill candidate.			
			bool nonPreservedFirst = true;															// Whether to alloc non-preserved first or last.

			if( this->getFunction()->isCaller() )
			{
				nonPreservedFirst = vdata->firstCallable == 0 || vdata->firstCallable->getOffset() >= vdata->lastEmittable->getOffset();
			}

			// Already Allocated

			// Go away if variable is already allocated.
			if( vdata->state == VARIABLE_STATE_REGISTER )
			{
				Cmp_unsigned__int32 oldIndex = vdata->registerIndex;

				// Already allocated in the right register.
				if( nsCodeQOR::maskFromIndex( oldIndex ) & regMask )
				{
					return;
				}

				// Try to find unallocated register first.
				mask = regMask & ~m_pState.usedXMM;
				if( mask != 0 )
				{
					idx = nsCodeQOR::findFirstBit( ( nonPreservedFirst && ( mask & ~preservedXMM ) != 0 ) ? mask & ~preservedXMM : mask );
				}				
				else		// Then find the allocated and later exchange.
				{
					idx = nsCodeQOR::findFirstBit( regMask & m_pState.usedXMM );
				}

				assert( idx != INVALID_VALUE );

				VarData* other = m_pState.xmm[ idx ];
				if( other )
				{
					spillXMMVar( other );
				}

				emitMoveVar( vdata, idx, vflags );
				_freedXMMRegister( oldIndex );
				m_pState.xmm[ idx ] = vdata;

				// Update VarData.
				vdata->state = VARIABLE_STATE_REGISTER;
				vdata->registerIndex = idx;
				vdata->homeRegisterIndex = idx;

				_allocatedXMMRegister( idx );
				return;
			}

			// Find Unused XMM
			// If regMask contains restricted registers which may be used then everything is handled in this block.
			if( regMask != nsCodeQOR::maskUpToIndex( REG_NUM_XMM ) )
			{
				// Try to find unallocated register first.
				mask = regMask & ~m_pState.usedXMM;
				if( mask != 0 )
				{
					idx = nsCodeQOR::findFirstBit( ( nonPreservedFirst && ( mask & ~preservedXMM ) != 0 ) ? mask & ~preservedXMM : mask );
					assert( idx != INVALID_VALUE );
				}				
				else		// Then find the allocated and later spill.
				{
					idx = nsCodeQOR::findFirstBit( regMask & m_pState.usedXMM );
					assert( idx != INVALID_VALUE );
					spillCandidate = m_pState.xmm[ idx ];		// Spill register we need.
					goto L_Spill;								// Jump to spill part of allocation.
				}
			}

			// Home register code.
			if( idx == INVALID_VALUE && home != INVALID_VALUE )
			{
				if( ( m_pState.usedXMM & ( 1U << home ) ) == 0 )
				{
					idx = home;
				}
			}

			if( idx == INVALID_VALUE )
			{
				for( i = 0, mask = ( 1 << i ); i < REG_NUM_XMM; i++, mask <<= 1 )
				{
					if( ( m_pState.usedXMM & mask ) == 0 )
					{
						// Convenience to alloc non-preserved first or non-preserved last.
						if( nonPreservedFirst )
						{
							if( idx != INVALID_VALUE && ( preservedXMM & mask ) != 0 )
							{
								continue;
							}
							idx = i;
							// If current register is preserved, we should try to find different
							// one that is not. This can save one push / pop in prolog / epilog.
							if( ( preservedXMM & mask ) == 0 )
							{
								break;
							}
						}
						else
						{
							if( idx != INVALID_VALUE && ( preservedXMM & mask ) == 0 )
							{
								continue;
							}
							idx = i;
							// The opposite.
							if( ( preservedXMM & mask ) != 0 )
							{
								break;
							}
						}
					}
				}
			}

			// Spill
			// If register is still not found, spill other variable.
			if( idx == INVALID_VALUE )
			{
				if( spillCandidate == 0 )
				{
					spillCandidate = _getSpillCandidateXMM();
				}

				// Spill candidate not found?
				if( spillCandidate == 0 )
				{
					( dynamic_cast< Cx86HLAssembler* >(m_pHLA) )->setError( ERROR_NOT_ENOUGH_REGISTERS );
					return;
				}

		L_Spill:

				// Prevented variables can't be spilled. _getSpillCandidate() never returns prevented variables, but when jumping to L_spill it can happen.
				if( spillCandidate->workOffset == m_uiCurrentOffset )
				{
					( dynamic_cast< Cx86HLAssembler* >(m_pHLA) )->setError( ERROR_REGISTERS_OVERLAP );
					return;
				}

				idx = spillCandidate->registerIndex;
				spillXMMVar( spillCandidate );
			}

			// Alloc

			if( vdata->state == VARIABLE_STATE_MEMORY && ( vflags & VARIABLE_ALLOC_READ ) != 0 )
			{
				emitLoadVar( vdata, idx );
			}

			// Update VarData.
			vdata->state = VARIABLE_STATE_REGISTER;
			vdata->registerIndex = idx;
			vdata->homeRegisterIndex = idx;
			
			_allocatedVariable( vdata );		// Update StateData.
		}

		//------------------------------------------------------------------------------
		void Cx86HLAContext::saveXMMVar( VarData* vdata ) __QCMP_THROW
		{
			// Can't save variable that isn't allocated.
			assert( vdata->state == VARIABLE_STATE_REGISTER );
			assert( vdata->registerIndex != INVALID_VALUE );

			Cmp_unsigned__int32 idx = vdata->registerIndex;
			emitSaveVar( vdata, idx );

			// Update VarData.
			vdata->changed = false;
		}

		//------------------------------------------------------------------------------
		void Cx86HLAContext::spillXMMVar( VarData* vdata ) __QCMP_THROW
		{
			// Can't spill variable that isn't allocated.
			assert( vdata->state == VARIABLE_STATE_REGISTER );
			assert( vdata->registerIndex != INVALID_VALUE );

			Cmp_unsigned__int32 idx = vdata->registerIndex;

			if( vdata->changed )
			{
				emitSaveVar( vdata, idx );
			}

			// Update VarData.
			vdata->registerIndex = static_cast< Cmp_unsigned__int32 >( INVALID_VALUE );
			vdata->state = VARIABLE_STATE_MEMORY;
			vdata->changed = false;

			// Update StateData.
			m_pState.xmm[ idx ] = 0;
			_freedXMMRegister( idx );
		}

		//------------------------------------------------------------------------------
		void Cx86HLAContext::emitLoadVar( VarData* vdata, Cmp_unsigned__int32 regIndex ) __QCMP_THROW
		{
			CMem m = _getVarMem( vdata );

			switch( vdata->type )
			{
			case VARIABLE_TYPE_GPD:
				{
					CGPReg IndexReg( gpd( regIndex ) );
					( dynamic_cast< Cx86HLAIntrinsics* >( m_pHLA ) )->emit( INST_MOV, &IndexReg, &m );
					if( m_bEmitComments )
					{
						goto addComment;
					}
					break;
				}
#if ( QOR_ARCH_WORDSIZE == 64 )
			case VARIABLE_TYPE_GPQ:
				{
					CGPReg IndexReg( gpq( regIndex ) );
					( dynamic_cast< Cx86HLAIntrinsics* >( m_pHLA ) )->emit( INST_MOV, &IndexReg, &m );
					if( m_bEmitComments )
					{
						goto addComment;
					}
					break;
				}
#endif // ASMJIT_X64

			case VARIABLE_TYPE_X87:
			case VARIABLE_TYPE_X87_1F:
			case VARIABLE_TYPE_X87_1D:
				// TODO: X87 VARIABLES NOT IMPLEMENTED.
				break;

			case VARIABLE_TYPE_MM:
				{
					CMMReg IndexReg( mm( regIndex ) );
					( dynamic_cast< Cx86HLAIntrinsics* >( m_pHLA ) )->emit( INST_MOVQ, &IndexReg, &m );
					if( m_bEmitComments )
					{
						goto addComment;
					}
					break;
				}
			case VARIABLE_TYPE_XMM:
				{
					CXMMReg IndexReg( xmm( regIndex ) );
					( dynamic_cast< Cx86HLAIntrinsics* >( m_pHLA ) )->emit( INST_MOVDQA, &IndexReg, &m );
					if( m_bEmitComments )
					{
						goto addComment;
					}
					break;
				}
			case VARIABLE_TYPE_XMM_1F:
				{
					CXMMReg IndexReg( xmm( regIndex ) );
					( dynamic_cast< Cx86HLAIntrinsics* >( m_pHLA ) )->emit( INST_MOVSS, &IndexReg, &m );
					if( m_bEmitComments )
					{
						goto addComment;
					}
					break;
				}
			case VARIABLE_TYPE_XMM_1D:
				{
					CXMMReg IndexReg( xmm( regIndex ) );
					( dynamic_cast< Cx86HLAIntrinsics* >( m_pHLA ) )->emit( INST_MOVSD, &IndexReg, &m );
					if( m_bEmitComments ) 
					{
						goto addComment;
					}
					break;
				}
			case VARIABLE_TYPE_XMM_4F:
				{
					CXMMReg IndexReg( xmm( regIndex ) );
					( dynamic_cast< Cx86HLAIntrinsics* >( m_pHLA ) )->emit( INST_MOVAPS, &IndexReg, &m );
					if( m_bEmitComments )
					{
						goto addComment;
					}
					break;
				}
			case VARIABLE_TYPE_XMM_2D:
				{
					CXMMReg IndexReg( xmm( regIndex ) );
					( dynamic_cast< Cx86HLAIntrinsics* >( m_pHLA ) )->emit( INST_MOVAPD, &IndexReg, &m );
					if( m_bEmitComments ) 
					{
						goto addComment;
					}
					break;
				}
			}
			return;

		addComment:
			( dynamic_cast< Cx86HLAssembler* >( m_pHLA ) )->getCurrentEmittable()->setCommentF( "Alloc %s", vdata->name );
		}

		//------------------------------------------------------------------------------
		void Cx86HLAContext::emitSaveVar( VarData* vdata, Cmp_unsigned__int32 regIndex ) __QCMP_THROW
		{
			// Caller must ensure that variable is allocated.
			assert( regIndex != INVALID_VALUE );

			CMem m = _getVarMem( vdata );

			switch( vdata->type )
			{
			case VARIABLE_TYPE_GPD:
				{
					CGPReg IndexReg( gpd( regIndex ) );
					( dynamic_cast< Cx86HLAIntrinsics* >( m_pHLA ) )->emit( INST_MOV, &m, &IndexReg );
					if( m_bEmitComments )
					{
						goto addComment;
					}
					break;
				}
#if ( QOR_ARCH_WORDSIZE == 64 )
			case VARIABLE_TYPE_GPQ:
				{
					CGPReg IndexReg( gpq( regIndex ) );
					( dynamic_cast< Cx86HLAIntrinsics* >( m_pHLA ) )->emit( INST_MOV, &m, &IndexReg );
					if( m_bEmitComments )
					{
						goto addComment;
					}
					break;
				}
#endif // ASMJIT_X64

			case VARIABLE_TYPE_X87:
			case VARIABLE_TYPE_X87_1F:
			case VARIABLE_TYPE_X87_1D:
				// TODO: X87 VARIABLES NOT IMPLEMENTED.
				break;

			case VARIABLE_TYPE_MM:
				{
					CMMReg IndexReg( mm( regIndex ) );
					( dynamic_cast< Cx86HLAIntrinsics* >( m_pHLA ) )->emit( INST_MOVQ, &m, &IndexReg );
					if( m_bEmitComments )
					{
						goto addComment;
					}
					break;
				}
			case VARIABLE_TYPE_XMM:
				{
					CXMMReg IndexReg( xmm( regIndex ) );
					( dynamic_cast< Cx86HLAIntrinsics* >( m_pHLA ) )->emit( INST_MOVDQA, &m, &IndexReg );
					if( m_bEmitComments )
					{
						goto addComment;
					}
					break;
				}
			case VARIABLE_TYPE_XMM_1F:
				{
					CXMMReg IndexReg( xmm( regIndex ) );
					( dynamic_cast< Cx86HLAIntrinsics* >( m_pHLA ) )->emit( INST_MOVSS, &m, &IndexReg );
					if( m_bEmitComments ) 
					{
						goto addComment;
					}
					break;
				}
			case VARIABLE_TYPE_XMM_1D:
				{
					CXMMReg IndexReg( xmm( regIndex ) );
					( dynamic_cast< Cx86HLAIntrinsics* >( m_pHLA ) )->emit( INST_MOVSD, &m, &IndexReg );
					if( m_bEmitComments )
					{
						goto addComment;
					}
					break;
				}
			case VARIABLE_TYPE_XMM_4F:
				{
					CXMMReg IndexReg( xmm( regIndex ) );
					( dynamic_cast< Cx86HLAIntrinsics* >( m_pHLA ) )->emit( INST_MOVAPS, &m, &IndexReg );
					if( m_bEmitComments )
					{
						goto addComment;
					}
					break;
				}
			case VARIABLE_TYPE_XMM_2D:
				{
					CXMMReg IndexReg( xmm( regIndex ) );
					( dynamic_cast< Cx86HLAIntrinsics* >( m_pHLA ) )->emit( INST_MOVAPD, &m, &IndexReg );
					if( m_bEmitComments ) 
					{
						goto addComment;
					}
					break;
				}
			}
			return;

		addComment:
			( dynamic_cast< Cx86HLAssembler* >( m_pHLA ) )->getCurrentEmittable()->setCommentF( "Spill %s", vdata->name );
		}

		//------------------------------------------------------------------------------
		void Cx86HLAContext::emitMoveVar( VarData* vdata, Cmp_unsigned__int32 regIndex, Cmp_unsigned__int32 vflags ) __QCMP_THROW
		{
			// Caller must ensure that variable is allocated.
			assert( vdata->registerIndex != INVALID_VALUE );

			if( ( vflags & VARIABLE_ALLOC_READ ) == 0 )
			{
				return;
			}

			switch( vdata->type )
			{
			case VARIABLE_TYPE_GPD:
				{
					CGPReg IndexReg( gpd( regIndex ) );
					CGPReg RegisterIndexReg( gpd( vdata->registerIndex ) );
					( dynamic_cast< Cx86HLAIntrinsics* >(m_pHLA) )->emit( INST_MOV, &IndexReg, &RegisterIndexReg );
				}
				break;
#if ( QOR_ARCH_WORDSIZE == 64 )
			case VARIABLE_TYPE_GPQ:
				{
					CGPReg IndexReg( gpq( regIndex ) );
					CGPReg RegisterIndexReg( gpq( vdata->registerIndex ) );
					( dynamic_cast< Cx86HLAIntrinsics* >(m_pHLA) )->emit(INST_MOV, &IndexReg, &RegisterIndexReg );
				}
				break;
#endif // ASMJIT_X64

			case VARIABLE_TYPE_X87:
			case VARIABLE_TYPE_X87_1F:
			case VARIABLE_TYPE_X87_1D:
				// TODO: X87 VARIABLES NOT IMPLEMENTED.
				break;

			case VARIABLE_TYPE_MM:
				{
					CMMReg IndexReg( mm( regIndex ) );
					CMMReg RegisterIndexReg( mm( vdata->registerIndex ) );
					( dynamic_cast< Cx86HLAIntrinsics* >( m_pHLA ) )->emit( INST_MOVQ, &IndexReg, &RegisterIndexReg );
				}
				break;

			case VARIABLE_TYPE_XMM:
				{
					CXMMReg IndexReg( xmm( regIndex ) );
					CXMMReg RegisterIndexReg( xmm( vdata->registerIndex ) );
					( dynamic_cast< Cx86HLAIntrinsics* >( m_pHLA ) )->emit( INST_MOVDQA, &IndexReg, &RegisterIndexReg );
				}
				break;
			case VARIABLE_TYPE_XMM_1F:
				{
					CXMMReg IndexReg( xmm( regIndex ) );
					CXMMReg RegisterIndexReg( xmm( vdata->registerIndex ) );
					( dynamic_cast< Cx86HLAIntrinsics* >( m_pHLA ) )->emit( INST_MOVSS, &IndexReg, &RegisterIndexReg );
				}
				break;
			case VARIABLE_TYPE_XMM_1D:
				{
					CXMMReg IndexReg( xmm( regIndex ) );
					CXMMReg RegisterIndexReg( xmm( vdata->registerIndex ) );
					( dynamic_cast< Cx86HLAIntrinsics* >( m_pHLA ) )->emit( INST_MOVSD, &IndexReg, &RegisterIndexReg );
				}
				break;
			case VARIABLE_TYPE_XMM_4F:
				{
					CXMMReg IndexReg( xmm( regIndex ) );
					CXMMReg RegisterIndexReg( xmm( vdata->registerIndex ) );
					( dynamic_cast< Cx86HLAIntrinsics* >( m_pHLA ) )->emit( INST_MOVAPS, &IndexReg, &RegisterIndexReg );
				}
				break;
			case VARIABLE_TYPE_XMM_2D:
				{
					CXMMReg IndexReg( xmm( regIndex ) );
					CXMMReg RegisterIndexReg( xmm( vdata->registerIndex ) );
					( dynamic_cast< Cx86HLAIntrinsics* >( m_pHLA ) )->emit( INST_MOVAPD, &IndexReg, &RegisterIndexReg );
				}
				break;
			}
		}

		//------------------------------------------------------------------------------
		void Cx86HLAContext::emitExchangeVar( VarData* vdata, Cmp_unsigned__int32 regIndex, Cmp_unsigned__int32 vflags, VarData* other ) __QCMP_THROW
		{
			// Caller must ensure that variable is allocated.
			assert( vdata->registerIndex != INVALID_VALUE );

			// If other is not valid then we can just emit MOV (or other similar instruction).
			if( other == 0 )
			{
				emitMoveVar( vdata, regIndex, vflags );
				return;
			}

			// If we need to alloc for write-only operation then we can move other
			// variable away instead of exchanging them.
			if( ( vflags & VARIABLE_ALLOC_READ ) == 0 )
			{
				emitMoveVar( other, vdata->registerIndex, VARIABLE_ALLOC_READ );
				return;
			}

			switch( vdata->type )
			{
			case VARIABLE_TYPE_GPD:
				{
					CGPReg IndexReg( gpd( regIndex ) );
					CGPReg RegisterIndexReg( gpd( vdata->registerIndex ) );
					( dynamic_cast< Cx86HLAIntrinsics* >( m_pHLA ) )->emit( INST_XCHG, &IndexReg, &RegisterIndexReg );
				}
				break;
#if ( QOR_ARCH_WORDSIZE == 64 )
			case VARIABLE_TYPE_GPQ:
				{
					CGPReg IndexReg( gpq( regIndex ) );
					CGPReg RegisterIndexReg( gpq( vdata->registerIndex ) );
					( dynamic_cast< Cx86HLAIntrinsics* >( m_pHLA ) )->emit( INST_XCHG, &IndexReg, &RegisterIndexReg );
				}
				break;
#endif // ASMJIT_X64

			case VARIABLE_TYPE_X87:
			case VARIABLE_TYPE_X87_1F:
			case VARIABLE_TYPE_X87_1D:
				// TODO: X87 VARIABLES NOT IMPLEMENTED.
				break;

				// NOTE: MM and XMM registers shoudln't be exchanged using this way, it's correct, but it sucks.

			case VARIABLE_TYPE_MM:
				{
					CMMReg a( mm( regIndex ) );
					CMMReg b( mm( vdata->registerIndex ) );

					( dynamic_cast< Cx86HLAIntrinsics* >( m_pHLA ) )->emit( INST_PXOR, &a, &b );
					( dynamic_cast< Cx86HLAIntrinsics* >( m_pHLA ) )->emit( INST_PXOR, &b, &a );
					( dynamic_cast< Cx86HLAIntrinsics* >( m_pHLA ) )->emit( INST_PXOR, &a, &b );
					break;
				}

			case VARIABLE_TYPE_XMM_1F:
			case VARIABLE_TYPE_XMM_4F:
				{
					CXMMReg a( xmm( regIndex ) );
					CXMMReg b( xmm( vdata->registerIndex ) );

					( dynamic_cast< Cx86HLAIntrinsics* >( m_pHLA ) )->emit( INST_XORPS, &a, &b );
					( dynamic_cast< Cx86HLAIntrinsics* >( m_pHLA ) )->emit( INST_XORPS, &b, &a );
					( dynamic_cast< Cx86HLAIntrinsics* >( m_pHLA ) )->emit( INST_XORPS, &a, &b );
					break;
				}

			case VARIABLE_TYPE_XMM_1D:
			case VARIABLE_TYPE_XMM_2D:
				{
					CXMMReg a( xmm( regIndex ) );
					CXMMReg b( xmm( vdata->registerIndex ) );

					( dynamic_cast< Cx86HLAIntrinsics* >( m_pHLA ) )->emit( INST_XORPD, &a, &b );
					( dynamic_cast< Cx86HLAIntrinsics* >( m_pHLA ) )->emit( INST_XORPD, &b, &a );
					( dynamic_cast< Cx86HLAIntrinsics* >( m_pHLA ) )->emit( INST_XORPD, &a, &b );
					break;
				}

			case VARIABLE_TYPE_XMM:
				{
					CXMMReg a( xmm( regIndex ) );
					CXMMReg b( xmm( vdata->registerIndex ) );

					( dynamic_cast< Cx86HLAIntrinsics* >( m_pHLA ) )->emit( INST_PXOR, &a, &b );
					( dynamic_cast< Cx86HLAIntrinsics* >( m_pHLA ) )->emit( INST_PXOR, &b, &a );
					( dynamic_cast< Cx86HLAIntrinsics* >( m_pHLA ) )->emit( INST_PXOR, &a, &b );
					break;
				}
			}
		}

		//------------------------------------------------------------------------------
		void Cx86HLAContext::_postAlloc( VarData* vdata, Cmp_unsigned__int32 vflags ) __QCMP_THROW
		{
			if( vflags & VARIABLE_ALLOC_WRITE )
			{
				vdata->changed = true;
			}
		}

		//------------------------------------------------------------------------------
		void Cx86HLAContext::_markMemoryUsed( VarData* vdata ) __QCMP_THROW
		{
			if( vdata->homeMemoryData != 0 )
			{
				return;
			}

			VarMemBlock* mem = _allocMemBlock( vdata->size );
			if( !mem )
			{
				return;
			}
			vdata->homeMemoryData = mem;
		}

		//------------------------------------------------------------------------------
		CMem Cx86HLAContext::_getVarMem( VarData* vdata ) __QCMP_THROW
		{
			CMem m;
			m.setId( vdata->id );
			if( !vdata->isMemArgument )
			{
				m.setDisplacement( m_iAdjustESP );
			}

			_markMemoryUsed( vdata );
			return m;
		}

		//------------------------------------------------------------------------------
		static Cmp__int32 getSpillScore( VarData* v, Cmp_unsigned__int32 currentOffset )
		{
			Cmp__int32 score = 0;

			assert( v->lastEmittable != 0 );
			Cmp_unsigned__int32 lastOffset = v->lastEmittable->getOffset();

			if( lastOffset >= currentOffset )
			{
				score += (Cmp__int32)( lastOffset - currentOffset );
			}

			score -= (Cmp__int32)v->registerWriteCount + (Cmp__int32)v->registerRWCount;		// Each write access decreases probability of spill.
			score += (Cmp__int32)v->registerReadCount;											// Each read-only access increases probability of spill.			
			score += (Cmp__int32)v->memoryWriteCount + (Cmp__int32)v->memoryRWCount;			// Each memory access increases probability of spill.
			score += (Cmp__int32)v->memoryReadCount;

			return score;
		}

		//------------------------------------------------------------------------------
		VarData* Cx86HLAContext::_getSpillCandidateGP() __QCMP_THROW
		{
			return _getSpillCandidateGeneric( m_pState.gp, REG_NUM_GP );
		}

		//------------------------------------------------------------------------------
		VarData* Cx86HLAContext::_getSpillCandidateMM() __QCMP_THROW
		{
			return _getSpillCandidateGeneric( m_pState.mm, REG_NUM_MM );
		}

		//------------------------------------------------------------------------------
		VarData* Cx86HLAContext::_getSpillCandidateXMM() __QCMP_THROW
		{
			return _getSpillCandidateGeneric( m_pState.xmm, REG_NUM_XMM );
		}

		//------------------------------------------------------------------------------
		VarData* Cx86HLAContext::_getSpillCandidateGeneric( VarData** varArray, Cmp_unsigned__int32 count ) __QCMP_THROW
		{
			Cmp_unsigned__int32 i;

			VarData* candidate = 0;
			Cmp_unsigned__int32 candidatePriority = 0;
			Cmp__int32 candidateScore = 0;

			Cmp_unsigned__int32 currentOffset = ( dynamic_cast< Cx86HLAssembler* >( m_pHLA ) )->getCurrentEmittable()->getOffset();

			for( i = 0; i < count; i++ )
			{
				VarData* vdata = varArray[ i ];		// Get variable.

				// Never spill variables needed for next instruction.
				if( vdata == 0 || vdata->workOffset == m_uiCurrentOffset )
				{
					continue;
				}

				Cmp_unsigned__int32 variablePriority = vdata->priority;
				Cmp__int32 variableScore = getSpillScore( vdata, currentOffset );

				if( ( candidate == 0 ) || ( variablePriority > candidatePriority ) || ( variablePriority == candidatePriority && variableScore > candidateScore ) )
				{
					candidate = vdata;
					candidatePriority = variablePriority;
					candidateScore = variableScore;
				}
			}

			return candidate;
		}

		//------------------------------------------------------------------------------
		void Cx86HLAContext::_addActive( VarData* vdata ) __QCMP_THROW
		{
			// Never call with variable that is already in active list.
			assert( vdata->nextActive == 0 );
			assert( vdata->prevActive == 0 );

			if( m_pActive == 0 )
			{
				vdata->nextActive = vdata;
				vdata->prevActive = vdata;
				m_pActive = vdata;
			}
			else
			{
				VarData* vlast = m_pActive->prevActive;

				vlast->nextActive = vdata;
				m_pActive->prevActive = vdata;

				vdata->nextActive = m_pActive;
				vdata->prevActive = vlast;
			}
		}

		//------------------------------------------------------------------------------
		void Cx86HLAContext::_freeActive( VarData* vdata ) __QCMP_THROW
		{
			VarData* next = vdata->nextActive;
			VarData* prev = vdata->prevActive;

			if (prev == next)
			{
				m_pActive = 0;
			}
			else
			{
				if( m_pActive == vdata )
				{
					m_pActive = next;
				}
				prev->nextActive = next;
				next->prevActive = prev;
			}

			vdata->nextActive = 0;
			vdata->prevActive = 0;
		}

		//------------------------------------------------------------------------------
		void Cx86HLAContext::_freeAllActive() __QCMP_THROW
		{
			if( m_pActive == 0 )
			{
				return;
			}

			VarData* cur = m_pActive;
			for(;;)
			{
				VarData* next = cur->nextActive;
				cur->nextActive = 0;
				cur->prevActive = 0;
				if( next == m_pActive ) 
				{
					break;
				}
			}

			m_pActive = 0;
		}

		//------------------------------------------------------------------------------
		void Cx86HLAContext::_allocatedVariable( VarData* vdata ) __QCMP_THROW
		{
			Cmp_unsigned__int32 idx = vdata->registerIndex;

			switch( vdata->type )
			{
			case VARIABLE_TYPE_GPD:
			case VARIABLE_TYPE_GPQ:
				m_pState.gp[ idx ] = vdata;
				_allocatedGPRegister( idx );
				break;

			case VARIABLE_TYPE_MM:
				m_pState.mm[ idx ] = vdata;
				_allocatedMMRegister( idx );
				break;

			case VARIABLE_TYPE_XMM:
			case VARIABLE_TYPE_XMM_1F:
			case VARIABLE_TYPE_XMM_4F:
			case VARIABLE_TYPE_XMM_1D:
			case VARIABLE_TYPE_XMM_2D:
				m_pState.xmm[ idx ] = vdata;
				_allocatedXMMRegister( idx );
				break;

			default:
				assert( 0 );
				break;
			}
		}

		//------------------------------------------------------------------------------
		void Cx86HLAContext::translateOperands( COperand** operands, Cmp_unsigned__int32 count ) __QCMP_THROW
		{
			Cmp_unsigned__int32 i;

			// Translate variables to registers.
			for( i = 0; i < count; i++ )
			{
				COperand* o = operands[ i ];

				if( o->isVar() )
				{
					VarData* vdata = ( dynamic_cast< Cx86HLAssembler* >(m_pHLA) )->_getVarData( o->getId() );
					assert( vdata != 0 );

					CBaseReg* pReg = new( ( dynamic_cast< Cx86HLAIntrinsics* >( m_pHLA ) )->getZone().zalloc( sizeof( CBaseReg ) ) ) CBaseReg( dynamic_cast< CBaseVar* >(o)->getRegisterCode() | vdata->registerIndex, o->getSize() );
					operands[ i ] = pReg;
					o = pReg;
					//o->m_Op = EOPERAND_REG;
					//dynamic_cast< CBaseReg* >(o)->m_Code |= vdata->registerIndex;
				}
				else if( o->isMem() )
				{
					if( ( o->getId() & OPERAND_ID_TYPE_MASK ) == OPERAND_ID_TYPE_VAR )
					{
						// Memory access. We just increment here actual displacement.
						VarData* vdata = ( dynamic_cast< Cx86HLAssembler* >(m_pHLA) )->_getVarData( o->getId() );
						assert( vdata != 0 );

						dynamic_cast< CMem* >(o)->setDisplacement( dynamic_cast< CMem* >(o)->getDisplacement() + ( vdata->isMemArgument ? m_iArgumentsActualDisp : m_iVariablesActualDisp ) );
						// NOTE: This is not enough, variable position will be patched later by Cx86HLAContext::_patchMemoryOperands().
					}
					else if( ( dynamic_cast< CMem* >(o)->getBase() & OPERAND_ID_TYPE_MASK ) == OPERAND_ID_TYPE_VAR )
					{
						VarData* vdata = ( dynamic_cast< Cx86HLAssembler* >( m_pHLA ) )->_getVarData( dynamic_cast< CMem* >(o)->getBase() );
						assert( vdata != 0 );
						dynamic_cast< CMem* >(o)->setBase( vdata->registerIndex );
					}

					if( ( dynamic_cast< CMem* >(o)->getIndex() & OPERAND_ID_TYPE_MASK ) == OPERAND_ID_TYPE_VAR )
					{
						VarData* vdata = ( dynamic_cast< Cx86HLAssembler* >( m_pHLA ) )->_getVarData( dynamic_cast< CMem* >(o)->getIndex() );
						assert( vdata != 0 );
						dynamic_cast< CMem* >(o)->setIndex( vdata->registerIndex );
					}
				}
			}
		}

		//------------------------------------------------------------------------------
		void Cx86HLAContext::addBackwardCode( CEJmp* from ) __QCMP_THROW
		{
			m_VecBackCode.append( from );
		}

		//------------------------------------------------------------------------------
		void Cx86HLAContext::addForwardJump( CEJmp* inst ) __QCMP_THROW
		{
			ForwardJumpData* j = reinterpret_cast< ForwardJumpData* >( m_Zone.zalloc( sizeof( ForwardJumpData ) ) );
			if( j == 0 ) 
			{ 
				( dynamic_cast< Cx86HLAssembler* >(m_pHLA) )->setError(ERROR_NO_HEAP_MEMORY); 
				return; 
			}

			j->inst = inst;
			j->state = _saveState();
			j->next = m_pForwardJumps;
			m_pForwardJumps = j;
		}

		//------------------------------------------------------------------------------
		StateData* Cx86HLAContext::_saveState() __QCMP_THROW
		{
			// Get count of variables stored in memory.
			Cmp_unsigned__int32 memVarsCount = 0;
			VarData* cur = m_pActive;
			if( cur )
			{
				do 
				{
					if( cur->state == VARIABLE_STATE_MEMORY )
					{
						memVarsCount++;
					}
					cur = cur->nextActive;
				} while( cur != m_pActive );
			}

			// Alloc StateData structure (using zone allocator) and copy current state into it.
			StateData* state = ( dynamic_cast< Cx86HLAssembler* >(m_pHLA) )->_newStateData( memVarsCount );
			memcpy( state, &m_pState, sizeof( StateData ) );

			// Clear changed flags.
			state->changedGP = 0;
			state->changedMM = 0;
			state->changedXMM = 0;

			Cmp_unsigned_int i;
			Cmp_unsigned_int mask;

			// Save variables stored in REGISTERs and CHANGE flag.
			for( i = 0, mask = 1; i < REG_NUM_GP; i++, mask <<= 1 )
			{
				if( state->gp[ i ] && state->gp[ i ]->changed )
				{
					state->changedGP |= mask;
				}
			}

			for( i = 0, mask = 1; i < REG_NUM_MM; i++, mask <<= 1 )
			{
				if( state->mm[ i ] && state->mm[ i ]->changed ) 
				{
					state->changedMM |= mask;
				}
			}

			for( i = 0, mask = 1; i < REG_NUM_XMM; i++, mask <<= 1 )
			{
				if( state->xmm[ i ] && state->xmm[ i ]->changed ) 
				{
					state->changedXMM |= mask;
				}
			}

			// Save variables stored in MEMORY.
			state->memVarsCount = memVarsCount;
			memVarsCount = 0;

			cur = m_pActive;
			if( cur )
			{
				do 
				{
					if( cur->state == VARIABLE_STATE_MEMORY )
					{
						state->memVarsData[ memVarsCount++ ] = cur;
					}
					cur = cur->nextActive;
				} while( cur != m_pActive );
			}

			// Finished.
			return state;
		}

		//------------------------------------------------------------------------------
		void Cx86HLAContext::_assignState( StateData* state ) __QCMP_THROW
		{
			memcpy( &m_pState, state, sizeof( StateData ) );
			m_pState.memVarsCount = 0;

			Cmp_unsigned_int i, mask;
			VarData* vdata;

			// Unuse all variables first.
			vdata = m_pActive;
			if( vdata )
			{
				do 
				{
					vdata->state = VARIABLE_STATE_UNUSED;
					vdata = vdata->nextActive;
				} while( vdata != m_pActive );
			}

			// Assign variables stored in memory which are not unused.
			for( i = 0; i < state->memVarsCount; i++ )
			{
				state->memVarsData[ i ]->state = VARIABLE_STATE_MEMORY;
			}

			// Assign allocated variables.
			for( i = 0, mask = 1; i < REG_NUM_GP; i++, mask <<= 1 )
			{
				if( ( vdata = m_pState.gp[ i ] ) != 0 )
				{
					vdata->state = VARIABLE_STATE_REGISTER;
					vdata->registerIndex = i;
					vdata->changed = ( m_pState.changedGP & mask ) != 0;
				}
			}

			for( i = 0, mask = 1; i < REG_NUM_MM; i++, mask <<= 1 )
			{
				if( ( vdata = m_pState.mm[ i ] ) != 0 )
				{
					vdata->state = VARIABLE_STATE_REGISTER;
					vdata->registerIndex = i;
					vdata->changed = ( m_pState.changedMM & mask ) != 0;
				}
			}

			for( i = 0, mask = 1; i < REG_NUM_XMM; i++, mask <<= 1 )
			{
				if( ( vdata = m_pState.xmm[ i ] ) != 0 )
				{
					vdata->state = VARIABLE_STATE_REGISTER;
					vdata->registerIndex = i;
					vdata->changed = ( m_pState.changedXMM & mask ) != 0;
				}
			}
		}

		//------------------------------------------------------------------------------
		void Cx86HLAContext::_restoreState( StateData* state, Cmp_unsigned__int32 targetOffset ) __QCMP_THROW
		{
			// 16 + 8 + 16 = GP + MMX + XMM registers.
			static const Cmp_unsigned_int STATE_REGS_COUNT = 16 + 8 + 16;

			StateData* fromState = &m_pState;
			StateData* toState = state;

			// No change, rare...
			if( fromState == toState )
			{
				return;
			}

			Cmp_unsigned_int base;
			Cmp_unsigned_int i;

			// Set target state to all variables. vdata->tempInt is target state in this
			// function.
			{
				// UNUSED.
				VarData* vdata = m_pActive;
				if( vdata )
				{
					do 
					{
						vdata->tempInt = VARIABLE_STATE_UNUSED;
						vdata = vdata->nextActive;
					} while( vdata != m_pActive );
				}

				// MEMORY.
				for( i = 0; i < toState->memVarsCount; i++ )
				{
					toState->memVarsData[ i ]->tempInt = VARIABLE_STATE_MEMORY;
				}

				// REGISTER.
				for( i = 0; i < StateData::NUM_REGS; i++ )
				{
					if( ( vdata = toState->regs[ i ] ) != 0 )
					{
						vdata->tempInt = VARIABLE_STATE_REGISTER;
					}
				}
			}

			// GP-Registers Switch

			// TODO.
#if 0
			for( i = 0; i < REG_NUM_GP; i++ )
			{
				VarData* fromVar = fromState->gp[ i ];
				VarData* toVar = toState->gp[ i ];

				if( fromVar != toVar )
				{
					if( fromVar != 0 )
					{
						if( toVar != 0 )
						{
							if (fromState->gp[to
						}
						else
						{
							// It is possible that variable that was saved in state currently not exists (tempInt is target scope!).
							if( fromVar->tempInt == VARIABLE_STATE_UNUSED )
							{
								unuseVar( fromVar, VARIABLE_STATE_UNUSED );
							}
							else
							{
								spillVar( fromVar );
							}
						}
					}
				}
				else if (fromVar != 0)
				{
					Cmp_unsigned__int32 mask = nsCodeQOR::maskFromIndex(i);
					// Variables are the same, we just need to compare changed flags.
					if( ( fromState->changedGP & mask ) && !( toState->changedGP & mask ) )
					{
						saveVar( fromVar );
					}
				}
			}
#endif

			// Spill.
			for( base = 0, i = 0; i < STATE_REGS_COUNT; i++ )
			{
				// Change the base offset (from base offset the register index can be
				// calculated).
				if( i == 16 || i == 16 + 8 )
				{
					base = i;
				}
				Cmp_unsigned__int32 regIndex = i - base;

				VarData* fromVar = fromState->regs[ i ];
				VarData* toVar = toState->regs[ i ];

				if( fromVar != toVar )
				{
					// Spill the register.
					if( fromVar != 0 )
					{
						// It is possible that variable that was saved in state currently not exists (tempInt is target scope!).
						if( fromVar->tempInt == VARIABLE_STATE_UNUSED )
						{
							unuseVar( fromVar, VARIABLE_STATE_UNUSED );
						}
						else
						{
							spillVar( fromVar );
						}
					}
				}
				else if( fromVar != 0 )
				{
					Cmp_unsigned__int32 mask = nsCodeQOR::maskFromIndex( regIndex );
					// Variables are the same, we just need to compare changed flags.
					if( ( fromState->changedGP & mask ) && !( toState->changedGP & mask ) )
					{
						saveVar( fromVar );
					}
				}
			}

			// Alloc.
			for( base = 0, i = 0; i < STATE_REGS_COUNT; i++ )
			{
				if( i == 16 || i == 24 )
				{
					base = i;
				}

				VarData* fromVar = fromState->regs[ i ];
				VarData* toVar = toState->regs[ i ];

				if( fromVar != toVar )
				{
					Cmp_unsigned__int32 regIndex = i - base;

					// Alloc register
					if( toVar != 0 )
					{
						allocVar( toVar, nsCodeQOR::maskFromIndex( regIndex ), VARIABLE_ALLOC_READ );
					}
				}

				// TODO:
				//if (toVar)
				//{
				// toVar->changed = to->changed;
				//}
			}

			// Update used masks.

			m_pState.usedGP = state->usedGP;
			m_pState.usedMM = state->usedMM;
			m_pState.usedXMM = state->usedXMM;

			// Update changed masks and cleanup.

			{
				VarData* vdata = m_pActive;
				if( vdata )
				{
					do 
					{
						if( vdata->tempInt != VARIABLE_STATE_REGISTER )
						{
							vdata->state = static_cast< Cmp_unsigned__int8 >( vdata->tempInt );
							vdata->changed = false;
						}

						vdata->tempInt = 0;
						vdata = vdata->nextActive;
					} while( vdata != m_pActive );
				}
			}
		}

		//------------------------------------------------------------------------------
		VarMemBlock* Cx86HLAContext::_allocMemBlock( Cmp_unsigned__int32 size ) __QCMP_THROW
		{
			assert( size != 0 );

			// First try to find mem blocks.
			VarMemBlock* mem = m_pMemFree;
			VarMemBlock* prev = 0;

			while( mem )
			{
				VarMemBlock* next = mem->nextFree;

				if( mem->size == size )
				{
					if( prev )
					{
						prev->nextFree = next;
					}
					else
					{
						m_pMemFree = next;
					}

					mem->nextFree = 0;
					return mem;
				}

				prev = mem;
				mem = next;
			}

			// Never mind, create new.
			mem = reinterpret_cast< VarMemBlock* >( m_Zone.zalloc( sizeof( VarMemBlock ) ) );
			if( !mem )
			{
				( dynamic_cast< Cx86HLAssembler* >(m_pHLA) )->setError( ERROR_NO_HEAP_MEMORY );
				return 0;
			}

			mem->offset = 0;
			mem->size = size;

			mem->nextUsed = m_pMemUsed;
			mem->nextFree = 0;

			m_pMemUsed = mem;

			switch( size )
			{
			case 16: 
				m_uiMem16BlocksCount++; 
				break;
			case 8: 
				m_uiMem8BlocksCount++; 
				break;
			case 4: 
				m_uiMem4BlocksCount++; 
				break;
			}

			return mem;
		}

		//------------------------------------------------------------------------------
		void Cx86HLAContext::_freeMemBlock( VarMemBlock* mem ) __QCMP_THROW
		{
			// Add mem to free blocks.
			mem->nextFree = m_pMemFree;
			m_pMemFree = mem;
		}

		//------------------------------------------------------------------------------
		void Cx86HLAContext::_allocMemoryOperands() __QCMP_THROW
		{
			VarMemBlock* mem;

			// Variables are allocated in this order:
			// 1. 16-byte variables.
			// 2. 8-byte variables.
			// 3. 4-byte variables.
			// 4. All others.

			Cmp_unsigned__int32 start16 = 0;
			Cmp_unsigned__int32 start8 = start16 + m_uiMem16BlocksCount * 16;
			Cmp_unsigned__int32 start4 = start8 + m_uiMem8BlocksCount * 8;
			Cmp_unsigned__int32 startX = ( start4 + m_uiMem4BlocksCount * 4 + 15 ) & ~15;

			for( mem = m_pMemUsed; mem; mem = mem->nextUsed )
			{
				Cmp_unsigned__int32 size = mem->size;
				Cmp_unsigned__int32 offset;

				switch( size )
				{
				case 16:
					offset = start16;
					start16 += 16;
					break;

				case 8:
					offset = start8;
					start8 += 8;
					break;

				case 4:
					offset = start4;
					start4 += 4;
					break;

				default:
					// Align to 16 bytes if size is 16 or more.
					if( size >= 16 )
					{
						size = ( size + 15 ) & ~15;
						startX = ( startX + 15 ) & ~15;
					}
					offset = startX;
					startX += size;
					break;
				}

				mem->offset = (Cmp__int32)offset;
				m_uiMemBytesTotal += size;
			}
		}

		//------------------------------------------------------------------------------
		void Cx86HLAContext::_patchMemoryOperands( nsArch::CEmittable* start, nsArch::CEmittable* stop ) __QCMP_THROW
		{
			nsArch::CEmittable* cur;

			for( cur = start;; cur = cur->getNext() )
			{
				if( cur->getType() == EMITTABLE_INSTRUCTION )
				{
					CMem* mem = ( dynamic_cast< CEInstruction* >( cur ) )->getMemOp();

					if( mem && ( mem->getId() & OPERAND_ID_TYPE_MASK ) == OPERAND_ID_TYPE_VAR )
					{
						VarData* vdata = ( dynamic_cast< Cx86HLAssembler* >( m_pHLA ) )->_getVarData( mem->getId() );
						assert( vdata != 0 );

						if( vdata->isMemArgument )
						{
							mem->setBase( m_uiArgumentsBaseReg );
							mem->setDisplacement( mem->getDisplacement() + vdata->homeMemoryOffset );
							mem->setDisplacement( mem->getDisplacement() + m_iArgumentsBaseOffset );
						}
						else
						{
							VarMemBlock* mb = reinterpret_cast< VarMemBlock* >( vdata->homeMemoryData );
							assert( mb != 0 );

							mem->setBase( m_uiVariablesBaseReg );
							mem->setDisplacement( mem->getDisplacement() + mb->offset );
							mem->setDisplacement( mem->getDisplacement() + m_iVariablesBaseOffset );
						}
					}
				}
				if( cur == stop ) 
				{
					break;
				}
			}
		}

	}//nsx86

}//nsArch

#endif//( QOR_ARCH == QOR_ARCH_X86_32 || QOR_ARCH == QOR_ARCH_X86_64 )
