//ECall.cpp

// Copyright (c) 2008-2010, Petr Kobalicek <kobalicek.petr@gmail.com>
// Copyright (c) Querysoft Limited 2012
//
// Permission is hereby granted, free of charge, to any person or organization
// obtaining a copy of the software and accompanying documentation covered by
// this license (the "Software") to use, reproduce, display, distribute,
// execute, and transmit the Software, and to prepare derivative works of the
// Software, and to permit third-parties to whom the Software is furnished to
// do so, all subject to the following:
//
// The copyright notices in the Software and this entire statement, including
// the above license grant, this restriction and the following disclaimer,
// must be included in all copies of the Software, in whole or in part, and
// all derivative works of the Software, unless such copies or derivative
// works are solely in the form of machine-executable object code generated by
// a source language processor.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
// FITNESS FOR A PARTICULAR PURPOSE, TITLE AND NON-INFRINGEMENT. IN NO EVENT
// SHALL THE COPYRIGHT HOLDERS OR ANYONE DISTRIBUTING THE SOFTWARE BE LIABLE
// FOR ANY DAMAGES OR OTHER LIABILITY, WHETHER IN CONTRACT, TORT OR OTHERWISE,
// ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
// DEALINGS IN THE SOFTWARE.

//x86PC specific high level call implementation

#include "ArchQOR.h"

#if		( QOR_ARCH == QOR_ARCH_X86_32 || QOR_ARCH == QOR_ARCH_X86_64 )

#include "ArchQOR/x86/HLAssembler/Emittables/ECall.h"
#include "ArchQOR/x86/HLAssembler/Emittables/EFunction.h"
#include "ArchQOR/x86/HLAssembler/x86HLAContext.h"
#include <string.h>
#include <assert.h>
#include <new>

//------------------------------------------------------------------------------
namespace nsArch
{
	//------------------------------------------------------------------------------
	namespace nsx86
	{
		//------------------------------------------------------------------------------
		CECall::CECall( nsArch::CHighLevelAssemblerBase* c, CEFunction* caller, const COperand* target ) __QCMP_THROW : CEmittable( c, EMITTABLE_CALL ),
		m_pCaller( caller ),
		m_paArgs( 0 ),
		m_GPParams( 0 ),
		m_MMParams( 0 ),
		m_XmmParams( 0 ),
		m_uiVariablesCount( 0 ),
		m_pVariables( 0 )
		{
			m_pTarget = target->Clone( ( dynamic_cast< Cx86HLAIntrinsics* >( getHLA() ) )->getZone() );
		}

		//------------------------------------------------------------------------------
		CECall::~CECall() __QCMP_THROW
		{
			memset( m_aArgumentToVarRecord, 0, sizeof( VarCallRecord* ) * FUNC_MAX_ARGS );
		}

		//------------------------------------------------------------------------------
		void CECall::prepare( CHLAssemblerContextBase& hlac ) __QCMP_THROW
		{
			Cx86HLAContext& cc = dynamic_cast< Cx86HLAContext& >( hlac );
			// Prepare is similar to EInstruction::prepare(). We collect unique variables
			// and update statistics, but we don't use standard alloc/free register calls.
			//
			// The calling function is also unique in variable allocator point of view,
			// because we need to alloc some variables that may be destroyed be the
			// callee (okay, may not, but this is not guaranteed).
			setOffset( cc.GetCurrentOffset() );

			// Tell CEFunction that another function will be called inside. It needs this
			// information to reserve stack for the call and to mark esp adjustable.
			getCaller()->reserveStackForFunctionCall( (Cmp__int32)getPrototype().getArgumentsStackSize() );

			Cmp_unsigned__int32 i;
			Cmp_unsigned__int32 argumentsCount = getPrototype().getArgumentsCount();
			Cmp_unsigned__int32 operandsCount = argumentsCount;
			Cmp_unsigned__int32 variablesCount = 0;

			// Create registers used as arguments mask.
			for( i = 0; i < argumentsCount; i++ )
			{
				const CFunctionPrototype::Argument& fArg = getPrototype().getArguments()[ i ];

				if( fArg.registerIndex != INVALID_VALUE )
				{
					switch( fArg.variableType )
					{
					case VARIABLE_TYPE_GPD:
					case VARIABLE_TYPE_GPQ:
						m_GPParams |= nsCodeQOR::maskFromIndex( fArg.registerIndex );
						break;
					case VARIABLE_TYPE_MM:
						m_MMParams |= nsCodeQOR::maskFromIndex( fArg.registerIndex );
						break;
					case VARIABLE_TYPE_XMM:
					case VARIABLE_TYPE_XMM_1F:
					case VARIABLE_TYPE_XMM_4F:
					case VARIABLE_TYPE_XMM_1D:
					case VARIABLE_TYPE_XMM_2D:
						m_XmmParams |= nsCodeQOR::maskFromIndex( fArg.registerIndex );
						break;
					default:
						assert( 0 );
					}
				}
				else
				{
					cc.getFunction()->mustAdjustEsp();
				}
			}

			// Call address.
			operandsCount++;

			// The first and the second return value.
			if( ! m_apRet[ 0 ]->isNone() )
			{
				operandsCount++;
			}
			if( ! m_apRet[ 1 ]->isNone() )
			{
				operandsCount++;
			}

#	define __GET_VARIABLE(__vardata__) \
	{ \
	VarData* _candidate = __vardata__; \
	\
	for (var = cur; ;) \
	{ \
	if (var == m_pVariables) \
	{ \
	var = cur++; \
	var->vdata = _candidate; \
	break; \
	} \
	\
	var--; \
	\
	if (var->vdata == _candidate) \
	{ \
	break; \
	} \
	} \
	\
	assert(var != 0); \
	}

			for( i = 0; i < operandsCount; i++ )
			{
				COperand* o = ( i < argumentsCount )  ? ( m_paArgs[ i ] ) : ( i == argumentsCount ? m_pTarget : m_apRet[ i - argumentsCount - 1 ] );

				if( o->isVar() )
				{
					assert( o->getId() != INVALID_VALUE );
					VarData* vdata = (dynamic_cast< Cx86HLAIntrinsics* >(m_pHLAssembler))->_getVarData(o->getId());
					assert(vdata != 0);

					if( vdata->workOffset == m_uiOffset )
					{
						continue;
					}

					if( !cc._isActive( vdata ) )
					{
						cc._addActive( vdata );
					}

					vdata->workOffset = m_uiOffset;
					variablesCount++;
				}
				else if( o->isMem() )
				{
					CMem* m( dynamic_cast< CMem* >(o) );
					if( ( m->getId() & OPERAND_ID_TYPE_MASK ) == OPERAND_ID_TYPE_VAR )
					{
						VarData* vdata = (dynamic_cast< Cx86HLAIntrinsics* >(m_pHLAssembler))->_getVarData( m->getId() );
						assert( vdata != 0 );

						cc._markMemoryUsed( vdata );
						if( !cc._isActive( vdata ) )
						{
							cc._addActive( vdata );
						}
						continue;
					}
					else if( ( m->getBase() & OPERAND_ID_TYPE_MASK ) == OPERAND_ID_TYPE_VAR )
					{
						VarData* vdata = (dynamic_cast< Cx86HLAIntrinsics* >(m_pHLAssembler))->_getVarData( m->getBase() );
						assert(vdata != 0);

						if( vdata->workOffset == m_uiOffset )
						{
							continue;
						}
						if( !cc._isActive( vdata ) )
						{
							cc._addActive( vdata );
						}

						vdata->workOffset = m_uiOffset;
						variablesCount++;
					}

					if( ( m->getIndex() & OPERAND_ID_TYPE_MASK ) == OPERAND_ID_TYPE_VAR )
					{
						VarData* vdata = (dynamic_cast< Cx86HLAIntrinsics* >(m_pHLAssembler))->_getVarData( m->getIndex() );
						assert( vdata != 0 );

						if( vdata->workOffset == m_uiOffset )
						{
							continue;
						}

						if( !cc._isActive( vdata ) )
						{
							cc._addActive( vdata );
						}

						vdata->workOffset = m_uiOffset;
						variablesCount++;
					}
				}
			}

			// Traverse all active variables and set their firstCallable pointer to this
			// call. This information can be used to choose between the preserved-first
			// and preserved-last register allocation.
			if( cc.getActive() )
			{
				VarData* first = cc.getActive();
				VarData* active = first;
				do
				{
					if( active->firstCallable == 0 )
					{
						active->firstCallable = this;
					}
					active = active->nextActive;
				} while( active != first );
			}

			if( !variablesCount )
			{
				cc.IncrementCurrentOffset();
				return;
			}

			m_pVariables = reinterpret_cast<VarCallRecord*>((dynamic_cast< Cx86HLAIntrinsics* >(m_pHLAssembler))->getZone().zalloc(sizeof(VarCallRecord) * variablesCount));
			if( !m_pVariables )
			{
				(dynamic_cast< Cx86HLAIntrinsics* >(m_pHLAssembler))->setError(ERROR_NO_HEAP_MEMORY);
				cc.IncrementCurrentOffset();
				return;
			}

			m_uiVariablesCount = variablesCount;
			memset(m_pVariables, 0, sizeof(VarCallRecord) * variablesCount);

			VarCallRecord* cur = m_pVariables;
			VarCallRecord* var = 0;

			for( i = 0; i < operandsCount; i++ )
			{
				COperand* o = (i < argumentsCount) ? ( m_paArgs[ i ] ) : ( i == argumentsCount ? m_pTarget : m_apRet[ i - argumentsCount - 1 ] );

				if( o->isVar() )
				{
					VarData* vdata = ( dynamic_cast< Cx86HLAIntrinsics* >( m_pHLAssembler ) )->_getVarData( o->getId() );
					assert( vdata != 0 );

					__GET_VARIABLE( vdata )
					m_aArgumentToVarRecord[ i ] = var;

					if( i < argumentsCount )
					{
						const CFunctionPrototype::Argument& fArg = getPrototype().getArguments()[i];

						if( fArg.registerIndex != INVALID_VALUE )
						{
							cc._newRegisterHomeIndex( vdata, fArg.registerIndex );

							switch( fArg.variableType )
							{
							case VARIABLE_TYPE_GPD:
							case VARIABLE_TYPE_GPQ:
								var->flags |= VarCallRecord::FLAG_IN_GP;
								var->inCount++;
								break;

							case VARIABLE_TYPE_MM:
								var->flags |= VarCallRecord::FLAG_IN_MM;
								var->inCount++;
								break;

							case VARIABLE_TYPE_XMM:
							case VARIABLE_TYPE_XMM_1F:
							case VARIABLE_TYPE_XMM_4F:
							case VARIABLE_TYPE_XMM_1D:
							case VARIABLE_TYPE_XMM_2D:
								var->flags |= VarCallRecord::FLAG_IN_XMM;
								var->inCount++;
								break;

							default:
								assert( 0 );
							}
						}
						else
						{
							var->inCount++;
						}

						vdata->registerReadCount++;
					}
					else if( i == argumentsCount )
					{
						Cmp_unsigned__int32 mask = ~getPrototype().getPreservedGP() & ~getPrototype().getPassedGP() & nsCodeQOR::maskUpToIndex( REG_NUM_GP );
						cc._newRegisterHomeIndex( vdata, nsCodeQOR::findFirstBit( mask ) );
						cc._newRegisterHomeMask( vdata, mask );

						var->flags |= VarCallRecord::FLAG_CALL_OPERAND_REG;
						vdata->registerReadCount++;
					}
					else
					{
						switch( vdata->type )
						{
						case VARIABLE_TYPE_GPD:
						case VARIABLE_TYPE_GPQ:
						{
							if( i == argumentsCount + 1 )
							{
								var->flags |= VarCallRecord::FLAG_OUT_EAX;
							}
							else
							{
								var->flags |= VarCallRecord::FLAG_OUT_EDX;
							}
						}
						break;

						case VARIABLE_TYPE_X87:
						case VARIABLE_TYPE_X87_1F:
						case VARIABLE_TYPE_X87_1D:
#	if ( QOR_ARCH_WORDSIZE == 32 )
						if( i == argumentsCount + 1 )
						{
							var->flags |= VarCallRecord::FLAG_OUT_ST0;
						}
						else
						{
							var->flags |= VarCallRecord::FLAG_OUT_ST1;
						}
#	else
						if( i == argumentsCount + 1 )
						{
							var->flags |= VarCallRecord::FLAG_OUT_XMM0;
						}
						else
						{
							var->flags |= VarCallRecord::FLAG_OUT_XMM1;
						}
#	endif
						break;

						case VARIABLE_TYPE_MM:
							var->flags |= VarCallRecord::FLAG_OUT_MM0;
							break;

						case VARIABLE_TYPE_XMM:
						case VARIABLE_TYPE_XMM_4F:
						case VARIABLE_TYPE_XMM_2D:
						{
							if( i == argumentsCount + 1 )
							{
								var->flags |= VarCallRecord::FLAG_OUT_XMM0;
							}
							else
							{
								var->flags |= VarCallRecord::FLAG_OUT_XMM1;
							}
						}
						break;

						case VARIABLE_TYPE_XMM_1F:
						case VARIABLE_TYPE_XMM_1D:
						{
#	if ( QOR_ARCH_WORDSIZE == 32 )
							if( i == argumentsCount + 1 )
							{
								var->flags |= VarCallRecord::FLAG_OUT_ST0;
							}
							else
							{
								var->flags |= VarCallRecord::FLAG_OUT_ST1;
							}
#	else
							if( i == argumentsCount + 1 )
							{
								var->flags |= VarCallRecord::FLAG_OUT_XMM0;
							}
							else
							{
								var->flags |= VarCallRecord::FLAG_OUT_XMM1;
							}
#	endif
						}
						break;

						default:
							assert( 0 );
						}

						vdata->registerWriteCount++;
					}
				}
				else if( o->isMem() )
				{
					CMem* m( dynamic_cast< CMem* >( o ) );
					assert(i == argumentsCount);

					if( ( m->getId() & OPERAND_ID_TYPE_MASK ) == OPERAND_ID_TYPE_VAR )
					{
						VarData* vdata = ( dynamic_cast< Cx86HLAIntrinsics* >( m_pHLAssembler ) )->_getVarData( m->getId() );
						assert( vdata != 0 );

						vdata->memoryReadCount++;
					}
					else if( ( m->getBase() & OPERAND_ID_TYPE_MASK ) == OPERAND_ID_TYPE_VAR )
					{
						VarData* vdata = ( dynamic_cast< Cx86HLAIntrinsics* >( m_pHLAssembler ) )->_getVarData( m->getBase() );
						assert( vdata != 0 );

						vdata->registerReadCount++;

						__GET_VARIABLE( vdata )
						var->flags |= VarCallRecord::FLAG_CALL_OPERAND_REG | VarCallRecord::FLAG_CALL_OPERAND_MEM;
					}

					if( ( m->getIndex() & OPERAND_ID_TYPE_MASK ) == OPERAND_ID_TYPE_VAR )
					{
						VarData* vdata = ( dynamic_cast< Cx86HLAIntrinsics* >( m_pHLAssembler ) )->_getVarData( m->getIndex() );
						assert( vdata != 0 );

						vdata->registerReadCount++;

						__GET_VARIABLE( vdata )
						var->flags |= VarCallRecord::FLAG_CALL_OPERAND_REG | VarCallRecord::FLAG_CALL_OPERAND_MEM;
					}
				}
			}

			//Traverse all variables and update firstEmittable / lastEmittable.
			//This function is called from iterator that scans emittables using forward direction so we can use this knowledge to optimize the process.

			//Same code is in EInstruction::prepare().
			for( i = 0; i < m_uiVariablesCount; i++ )
			{
				VarData* v = m_pVariables[ i ].vdata;

				if( v->firstEmittable == 0 )		// First emittable (begin of variable scope).
				{
					v->firstEmittable = this;
				}

				v->lastEmittable = this;			// Last emittable (end of variable scope).
			}

			cc.IncrementCurrentOffset();

#	undef __GET_VARIABLE
		}

		//------------------------------------------------------------------------------
		nsArch::CEmittable* CECall::translate( CHLAssemblerContextBase& hlac ) __QCMP_THROW
		{
			Cx86HLAContext& cc = dynamic_cast< Cx86HLAContext& >( hlac );

			Cmp_unsigned__int32 i;
			Cmp_unsigned__int32 preserved, mask;

			Cmp_unsigned__int32 temporaryGpReg;
			Cmp_unsigned__int32 temporaryXmmReg;

			Cmp_unsigned__int32 offset = cc.GetCurrentOffset();
			Cx86HLAIntrinsics* compiler = dynamic_cast< Cx86HLAIntrinsics* >( cc.getHighLevelAssembler() );

			// Constants.
			const CFunctionPrototype::Argument* targs = getPrototype().getArguments();

			Cmp_unsigned__int32 argumentsCount = getPrototype().getArgumentsCount();
			Cmp_unsigned__int32 variablesCount = m_uiVariablesCount;

			// Processed arguments.
			Cmp_unsigned__int8 processed[ FUNC_MAX_ARGS ] = { 0 };

			compiler->comment( "Function Call" );

			// These variables are used by the instruction and we set current offset
			// to their work offsets -> The getSpillCandidate() method never returns the variable used by this instruction.
			for( i = 0; i < variablesCount; i++ )
			{
				m_pVariables[ i ].vdata->workOffset = offset;
				m_pVariables[ i ].vdata->tempPtr = &m_pVariables[ i ];		// Init back-reference to VarCallRecord.
			}

			// STEP 1:
			// Spill variables which are not used by the function call and have to be destroyed. These registers may be used by callee.

			preserved = getPrototype().getPreservedGP();
			for( i = 0, mask = 1; i < REG_NUM_GP; i++, mask <<= 1 )
			{
				VarData* vdata = cc.m_pState.gp[ i ];
				if( vdata && vdata->workOffset != offset && ( preserved & mask ) == 0 )
				{
					cc.spillGPVar( vdata );
				}
			}

			preserved = getPrototype().getPreservedMM();
			for( i = 0, mask = 1; i < REG_NUM_MM; i++, mask <<= 1 )
			{
				VarData* vdata = cc.m_pState.mm[ i ];
				if( vdata && vdata->workOffset != offset && ( preserved & mask ) == 0 )
				{
					cc.spillMMVar( vdata );
				}
			}

			preserved = getPrototype().getPreservedXMM();
			for( i = 0, mask = 1; i < REG_NUM_XMM; i++, mask <<= 1 )
			{
				VarData* vdata = cc.m_pState.xmm[ i ];
				if( vdata && vdata->workOffset != offset && ( preserved & mask ) == 0 )
				{
					cc.spillXMMVar( vdata );
				}
			}

			// STEP 2:
			// Move all arguments to the stack which all already in registers.
			for( i = 0; i < argumentsCount; i++ )
			{
				if( processed[ i ] )
				{
					continue;
				}

				const CFunctionPrototype::Argument& argType = targs[ i ];
				if( argType.registerIndex != INVALID_VALUE )
				{
					continue;
				}

				COperand* operand = m_paArgs[ i ];

				if( operand->isVar() )
				{
					VarCallRecord* rec = m_aArgumentToVarRecord[ i ];
					VarData* vdata = compiler->_getVarData( operand->getId() );

					if( vdata->registerIndex != INVALID_VALUE )
					{
						_moveAllocatedVariableToStack( cc, vdata, argType );
						rec->inDone++;
						processed[ i ] = true;
					}
				}
			}

			// STEP 3:
			// Spill all non-preserved variables we moved to stack in STEP #2.
			for( i = 0; i < argumentsCount; i++ )
			{
				VarCallRecord* rec = m_aArgumentToVarRecord[ i ];
				if( !rec || processed[ i ] )
				{
					continue;
				}

				if( rec->inDone >= rec->inCount )
				{
					VarData* vdata = rec->vdata;
					if( vdata->registerIndex == INVALID_VALUE )
					{
						continue;
					}

					if( rec->outCount )
					{
						// Variable will be rewritten by function return value, it's not needed to spill it. It will be allocated again by ECall.
						cc.unuseVar( rec->vdata, VARIABLE_STATE_UNUSED );
					}
					else
					{
						switch( vdata->type )
						{
						case VARIABLE_TYPE_GPD:
						case VARIABLE_TYPE_GPQ:
						{
							if( ( getPrototype().getPreservedGP() & nsCodeQOR::maskFromIndex( vdata->registerIndex ) ) == 0 )
							{
								cc.spillGPVar( vdata );
							}
							break;
						}
						case VARIABLE_TYPE_MM:
						{
							if( ( getPrototype().getPreservedMM() & nsCodeQOR::maskFromIndex( vdata->registerIndex ) ) == 0 )
							{
								cc.spillMMVar( vdata );
							}
							break;
						}
						case VARIABLE_TYPE_XMM:
						case VARIABLE_TYPE_XMM_1F:
						case VARIABLE_TYPE_XMM_1D:
						case VARIABLE_TYPE_XMM_4F:
						case VARIABLE_TYPE_XMM_2D:
						{
							if( ( getPrototype().getPreservedXMM() & nsCodeQOR::maskFromIndex( vdata->registerIndex ) ) == 0 )
							{
								cc.spillXMMVar( vdata );
							}
							break;
						}
						}
					}
				}
			}

			// STEP 4:
			// Get temporary register that we can use to pass input function arguments.
			// Now it's safe to do, because the non-needed variables should be spilled.
			temporaryGpReg = _findTemporaryGpRegister( cc );
			temporaryXmmReg = _findTemporaryXmmRegister( cc );

			// If failed to get temporary register then we need just to pick one.
			if( temporaryGpReg == INVALID_VALUE )
			{
				// TODO:
			}

			if( temporaryXmmReg == INVALID_VALUE )
			{
				// TODO:
			}

			// STEP 5:
			// Move all remaining arguments to the stack (we can use temporary register).
			// or allocate it to the primary register. Also move immediates.
			for( i = 0; i < argumentsCount; i++ )
			{
				if( processed[ i ] )
				{
					continue;
				}

				const CFunctionPrototype::Argument& argType = targs[ i ];
				if( argType.registerIndex != INVALID_VALUE )
				{
					continue;
				}

				COperand* operand = m_paArgs[ i ];

				if( operand->isVar() )
				{
					VarCallRecord* rec = m_aArgumentToVarRecord[ i ];
					VarData* vdata = compiler->_getVarData( operand->getId() );
					_moveSpilledVariableToStack( cc, vdata, argType, temporaryGpReg, temporaryXmmReg );
					rec->inDone++;
					processed[ i ] = true;
				}
				else if( operand->isImm() )
				{
					//int todo = 1;
					//TODO:
				}
			}

			// STEP 6:
			// Allocate arguments to registers.
			bool didWork;

			do
			{
				didWork = false;

				for( i = 0; i < argumentsCount; i++ )
				{
					if( processed[ i ] )
					{
						continue;
					}

					VarCallRecord* rsrc = m_aArgumentToVarRecord[ i ];

					COperand* osrc = m_paArgs[ i ];
					assert( osrc->isVar() );
					VarData* vsrc = compiler->_getVarData( osrc->getId() );

					const CFunctionPrototype::Argument& srcArgType = targs[ i ];
					VarData* vdst = _getOverlappingVariable( cc, srcArgType );

					if( vsrc == vdst )
					{
						rsrc->inDone++;
						processed[ i ] = true;

						didWork = true;
						continue;
					}
					else if( vdst != 0 )
					{
						VarCallRecord* rdst = reinterpret_cast< VarCallRecord* >( vdst->tempPtr );

						if( rdst->inDone >= rdst->inCount && ( rdst->flags & VarCallRecord::FLAG_CALL_OPERAND_REG ) == 0 )
						{
							// Safe to spill.
							if( rdst->outCount || vdst->lastEmittable == this )
							{
								cc.unuseVar( vdst, VARIABLE_STATE_UNUSED );
							}
							else
							{
								cc.spillVar( vdst );
							}
							vdst = 0;
						}
						else
						{
							Cmp_unsigned__int32 x = getPrototype().findArgumentByRegisterCode( getVariableRegisterCode( vsrc->type, vsrc->registerIndex ) );
							bool doSpill = true;

							if( ( getVariableClass( vdst->type ) & VariableInfo::CLASS_GP ) != 0 )
							{
								// Try to emit mov to register which is possible for call() operand.
								if( x == INVALID_VALUE && ( rdst->flags & VarCallRecord::FLAG_CALL_OPERAND_REG ) != 0 )
								{
									Cmp_unsigned__int32 rIndex;
									Cmp_unsigned__int32 rBit;

									// The mask which contains registers which are not-preserved
									// (these that might be clobbered by the callee) and which are
									// not used to pass function arguments. Each register contained
									// in this mask is ideal to be used by call() instruction.
									Cmp_unsigned__int32 possibleMask = ~getPrototype().getPreservedGP() & ~getPrototype().getPassedGP() & nsCodeQOR::maskUpToIndex( REG_NUM_GP );

									if( possibleMask != 0 )
									{
										for( rIndex = 0, rBit = 1; rIndex < REG_NUM_GP; rIndex++, rBit <<= 1 )
										{
											if( ( possibleMask & rBit ) != 0 )
											{
												if( cc.m_pState.gp[ rIndex ] == 0 )
												{
													// This is the best possible solution, the register is free.
													// We do not need to continue with this loop, the rIndex will be used by the call().
													break;
												}
												else
												{
													// Wait until the register is freed or try to find another.
													doSpill = false;
													didWork = true;
												}
											}
										}
									}
									else
									{
										// Try to find a register which is free and which is not used to pass a function argument.
										possibleMask = getPrototype().getPreservedGP();

										for( rIndex = 0, rBit = 1; rIndex < REG_NUM_GP; rIndex++, rBit <<= 1 )
										{
											if( ( possibleMask & rBit ) != 0 )
											{
												// Found one.
												if( cc.m_pState.gp[ rIndex ] == 0 )
												{
													break;
												}
											}
										}
									}

									if( rIndex < REG_NUM_GP )
									{
										if( temporaryGpReg == vsrc->registerIndex )
										{
											temporaryGpReg = rIndex;
										}
										CGPReg IndexReg( gpn( rIndex ) );
										CGPReg RegisterIndexReg( gpn( vsrc->registerIndex ) );
										compiler->emit( INST_MOV, &IndexReg, &RegisterIndexReg );

										cc.m_pState.gp[ vsrc->registerIndex ] = 0;
										cc.m_pState.gp[ rIndex ] = vsrc;

										vsrc->registerIndex = rIndex;
										cc._allocatedGPRegister( rIndex );

										doSpill = false;
										didWork = true;
									}
								}
								// Emit xchg instead of spill/alloc if possible.
								else if( x != INVALID_VALUE )
								{
									const CFunctionPrototype::Argument& dstArgType = targs[ x ];
									if( getVariableClass( dstArgType.variableType ) == getVariableClass( srcArgType.variableType ) )
									{
										Cmp_unsigned__int32 dstIndex = vdst->registerIndex;
										Cmp_unsigned__int32 srcIndex = vsrc->registerIndex;

										if (srcIndex == dstArgType.registerIndex && srcIndex < 16 )
										{
#		if ( QOR_ARCH_WORDSIZE == 64 )
											if( vdst->type != VARIABLE_TYPE_GPD || vsrc->type != VARIABLE_TYPE_GPD )
											{
												CGPReg DstIndexReg( gpq( dstIndex ) );
												CGPReg SrcIndexReg( gpq( srcIndex ) );
												compiler->emit( INST_XCHG, &DstIndexReg, &SrcIndexReg );
											}
											else
#		endif
											{
												CGPReg DstIndexReg( gpd( dstIndex ) );
												CGPReg SrcIndexReg( gpd( srcIndex ) );
												compiler->emit( INST_XCHG, &DstIndexReg, &SrcIndexReg );
											}

											cc.m_pState.gp[ srcIndex ] = vdst;
											cc.m_pState.gp[ dstIndex ] = vsrc;

											vdst->registerIndex = srcIndex;
											vsrc->registerIndex = dstIndex;

											rdst->inDone++;
											rsrc->inDone++;

											processed[ i ] = true;
											processed[ x ] = true;

											doSpill = false;
										}
									}
								}
							}

							if( doSpill )
							{
								cc.spillVar( vdst );
								vdst = 0;
							}
						}
					}

					if( vdst == 0 )
					{
						VarCallRecord* rec = reinterpret_cast< VarCallRecord* >( vsrc->tempPtr );

						_moveSrcVariableToRegister( cc, vsrc, srcArgType );

						switch( srcArgType.variableType )
						{
						case VARIABLE_TYPE_GPD:
						case VARIABLE_TYPE_GPQ:
							cc._markGPRegisterModified( srcArgType.registerIndex );
							break;
						case VARIABLE_TYPE_MM:
							cc._markMMRegisterModified( srcArgType.registerIndex );
							break;
						case VARIABLE_TYPE_XMM:
						case VARIABLE_TYPE_XMM_1F:
						case VARIABLE_TYPE_XMM_1D:
						case VARIABLE_TYPE_XMM_4F:
						case VARIABLE_TYPE_XMM_2D:
							cc._markMMRegisterModified( srcArgType.registerIndex );
							break;
						}

						rec->inDone++;
						processed[ i ] = true;
					}
				}
			} while( didWork );

			// STEP 7:
			// Allocate operand used by CALL instruction.
			for( i = 0; i < variablesCount; i++ )
			{
				VarCallRecord& r = m_pVariables[ i ];
				if( ( r.flags & VarCallRecord::FLAG_CALL_OPERAND_REG ) && ( r.vdata->registerIndex == INVALID_VALUE ) )
				{
					// If the register is not allocated and the call form is 'call reg' then it's possible to keep it in memory.
					if( ( r.flags & VarCallRecord::FLAG_CALL_OPERAND_MEM ) == 0 )
					{
						m_pTarget = GPVarFromData( r.vdata ).m().Clone( ( dynamic_cast< Cx86HLAIntrinsics* >( getHLA() ) )->getZone() );
						break;
					}

					if( temporaryGpReg == INVALID_VALUE )
					{
						temporaryGpReg = _findTemporaryGpRegister( cc );
					}

					cc.allocGPVar( r.vdata, nsCodeQOR::maskFromIndex( temporaryGpReg ), VARIABLE_ALLOC_REGISTER | VARIABLE_ALLOC_READ );
				}
			}

			cc.translateOperands( &m_pTarget, 1 );

			// STEP 8:
			// Spill all preserved variables.
			preserved = getPrototype().getPreservedGP();
			for( i = 0, mask = 1; i < REG_NUM_GP; i++, mask <<= 1 )
			{
				VarData* vdata = cc.m_pState.gp[ i ];
				if( vdata && ( preserved & mask ) == 0 )
				{
					VarCallRecord* rec = reinterpret_cast< VarCallRecord* >( vdata->tempPtr );
					if( rec && ( rec->outCount || rec->flags & VarCallRecord::FLAG_UNUSE_AFTER_USE || vdata->lastEmittable == this ) )
					{
						cc.unuseVar( vdata, VARIABLE_STATE_UNUSED );
					}
					else
					{
						cc.spillGPVar( vdata );
					}
				}
			}

			preserved = getPrototype().getPreservedMM();
			for( i = 0, mask = 1; i < REG_NUM_MM; i++, mask <<= 1 )
			{
				VarData* vdata = cc.m_pState.mm[ i ];
				if( vdata && ( preserved & mask ) == 0 )
				{
					VarCallRecord* rec = reinterpret_cast< VarCallRecord* >( vdata->tempPtr );
					if( rec && ( rec->outCount || vdata->lastEmittable == this ) )
					{
						cc.unuseVar( vdata, VARIABLE_STATE_UNUSED );
					}
					else
					{
						cc.spillMMVar( vdata );
					}
				}
			}

			preserved = getPrototype().getPreservedXMM();
			for( i = 0, mask = 1; i < REG_NUM_XMM; i++, mask <<= 1 )
			{
				VarData* vdata = cc.m_pState.xmm[ i ];
				if( vdata && ( preserved & mask ) == 0 )
				{
					VarCallRecord* rec = reinterpret_cast< VarCallRecord* >( vdata->tempPtr );
					if( rec && ( rec->outCount || vdata->lastEmittable == this ) )
					{
						cc.unuseVar( vdata, VARIABLE_STATE_UNUSED );
					}
					else
					{
						cc.spillXMMVar( vdata );
					}
				}
			}

			// STEP 9:
			// Emit CALL instruction.
			compiler->emit( INST_CALL, m_pTarget );

			// Restore the stack offset.
			if( getPrototype().getCalleePopsStack() )
			{
				Cmp__int32 s = (Cmp__int32)getPrototype().getArgumentsStackSize();
				if( s )
				{
					CImm Imms( imm( s ) );
					compiler->emit( INST_SUB, &Cx86CPUCore::nsp, &Imms );
				}
			}

			// STEP 10:
			// Prepare others for return value(s) and cleanup.
			// Clear temp data, see VarData::temp why it's needed.
			for( i = 0; i < variablesCount; i++ )
			{
				VarCallRecord* rec = &m_pVariables[ i ];
				VarData* vdata = rec->vdata;

				if( rec->flags & ( VarCallRecord::FLAG_OUT_EAX | VarCallRecord::FLAG_OUT_EDX ) )
				{
					if( getVariableClass( vdata->type ) & VariableInfo::CLASS_GP )
					{
						cc.allocGPVar( vdata, nsCodeQOR::maskFromIndex( ( rec->flags & VarCallRecord::FLAG_OUT_EAX ) != 0 ? REG_INDEX_EAX : REG_INDEX_EDX ), VARIABLE_ALLOC_REGISTER | VARIABLE_ALLOC_WRITE );
						vdata->changed = true;
					}
				}

				if( rec->flags & ( VarCallRecord::FLAG_OUT_MM0 ) )
				{
					if( getVariableClass( vdata->type ) & VariableInfo::CLASS_MM )
					{
						cc.allocMMVar( vdata, nsCodeQOR::maskFromIndex( REG_INDEX_MM0 ), VARIABLE_ALLOC_REGISTER | VARIABLE_ALLOC_WRITE );
						vdata->changed = true;
					}
				}

				if( rec->flags & ( VarCallRecord::FLAG_OUT_XMM0 | VarCallRecord::FLAG_OUT_XMM1 ) )
				{
					if( getVariableClass( vdata->type ) & VariableInfo::CLASS_XMM )
					{
						cc.allocXMMVar( vdata, nsCodeQOR::maskFromIndex( ( rec->flags & VarCallRecord::FLAG_OUT_XMM0 ) != 0 ? REG_INDEX_XMM0 : REG_INDEX_XMM1 ), VARIABLE_ALLOC_REGISTER | VARIABLE_ALLOC_WRITE );
						vdata->changed = true;
					}
				}

				if( rec->flags & ( VarCallRecord::FLAG_OUT_ST0 | VarCallRecord::FLAG_OUT_ST1 ) )
				{
					if( getVariableClass( vdata->type ) & VariableInfo::CLASS_XMM )
					{
						CMem mem( cc._getVarMem( vdata ) );
						cc.unuseVar( vdata, VARIABLE_STATE_MEMORY );

						switch( vdata->type )
						{
						case VARIABLE_TYPE_XMM_1F:
						case VARIABLE_TYPE_XMM_4F:
						{
							mem.setSize( 4 );
							compiler->emit( INST_FSTP, &mem );
							break;
						}
						case VARIABLE_TYPE_XMM_1D:
						case VARIABLE_TYPE_XMM_2D:
						{
							mem.setSize( 8 );
							compiler->emit( INST_FSTP, &mem );
							break;
						}
						default:
						{
							compiler->comment( "*** WARNING: Can't convert float return value to untyped XMM\n" );
							break;
						}
						}
					}
				}

				// Cleanup.
				vdata->tempPtr = 0;
			}

			for( i = 0; i < variablesCount; i++ )
			{
				cc._unuseVarOnEndOfScope( this, &m_pVariables[ i ] );
			}

			return translated();
		}

		//------------------------------------------------------------------------------
		int CECall::getMaxSize() const __QCMP_THROW
		{
			// TODO: Not optimal.
			return 15;
		}

		//------------------------------------------------------------------------------
		bool CECall::tryUnuseVar( nsArch::CommonVarData* vdata ) __QCMP_THROW
		{
			VarData* v = reinterpret_cast< VarData* >( vdata );
			for( Cmp_unsigned__int32 i = 0; i < m_uiVariablesCount; i++ )
			{
				if( m_pVariables[ i ].vdata == v )
				{
					m_pVariables[ i ].flags |= VarCallRecord::FLAG_UNUSE_AFTER_USE;
					return true;
				}
			}

			return false;
		}

		//------------------------------------------------------------------------------
		Cmp_unsigned__int32 CECall::_findTemporaryGpRegister( Cx86HLAContext& cc ) __QCMP_THROW
		{
			Cmp_unsigned__int32 i;
			Cmp_unsigned__int32 mask;

			Cmp_unsigned__int32 passedGP = getPrototype().getPassedGP();
			Cmp_unsigned__int32 candidate = static_cast< Cmp_unsigned__int32 >( INVALID_VALUE );

			// Find all registers used to pass function arguments.
			// We shouldn't use these if possible.
			for( i = 0, mask = 1; i < REG_NUM_GP; i++, mask <<= 1 )
			{
				if( cc.m_pState.gp[ i ] == 0 )
				{
					// If this register is used to pass arguments to function, we will mark
					// it and use it only if there is no other one.
					if( ( passedGP & mask ) != 0 )
					{
						candidate = i;
					}
					else
					{
						return i;
					}
				}
			}

			return candidate;
		}

		//------------------------------------------------------------------------------
		Cmp_unsigned__int32 CECall::_findTemporaryXmmRegister( Cx86HLAContext& cc ) __QCMP_THROW
		{
			Cmp_unsigned__int32 i;
			Cmp_unsigned__int32 mask;

			Cmp_unsigned__int32 passedXMM = getPrototype().getPassedXMM();
			Cmp_unsigned__int32 candidate = static_cast< Cmp_unsigned__int32 >( INVALID_VALUE );

			// Find all registers used to pass function arguments.
			// We shouldn't use these if possible.
			for( i = 0, mask = 1; i < REG_NUM_XMM; i++, mask <<= 1 )
			{
				if( cc.m_pState.xmm[ i ] == 0 )
				{
					// If this register is used to pass arguments to function, we will mark it and use it only if there is no other one.
					if( ( passedXMM & mask ) != 0 )
					{
						candidate = i;
					}
					else
					{
						return i;
					}
				}
			}

			return candidate;
		}

		//------------------------------------------------------------------------------
		VarData* CECall::_getOverlappingVariable( Cx86HLAContext& cc, const CFunctionPrototype::Argument& argType ) const __QCMP_THROW
		{
			assert( argType.variableType != INVALID_VALUE );

			switch( argType.variableType )
			{
			case VARIABLE_TYPE_GPD:
			case VARIABLE_TYPE_GPQ:
				return cc.m_pState.gp[ argType.registerIndex ];
			case VARIABLE_TYPE_MM:
				return cc.m_pState.mm[ argType.registerIndex ];
			case VARIABLE_TYPE_XMM:
			case VARIABLE_TYPE_XMM_1F:
			case VARIABLE_TYPE_XMM_1D:
			case VARIABLE_TYPE_XMM_4F:
			case VARIABLE_TYPE_XMM_2D:
				return cc.m_pState.xmm[ argType.registerIndex ];
			}

			return 0;
		}

		//------------------------------------------------------------------------------
		void CECall::_moveAllocatedVariableToStack( Cx86HLAContext& cc, VarData* vdata, const CFunctionPrototype::Argument& argType ) __QCMP_THROW
		{
			assert( argType.registerIndex == INVALID_VALUE );
			assert( vdata->registerIndex != INVALID_VALUE );

			Cx86HLAIntrinsics* compiler = dynamic_cast< Cx86HLAIntrinsics* >( cc.getHighLevelAssembler() );

			Cmp_unsigned__int32 src = vdata->registerIndex;
			CMem dst = ptr( Cx86CPUCore::nsp, -(int)sizeof( Cmp_int_ptr ) + argType.stackOffset );

			switch( vdata->type )
			{
			case VARIABLE_TYPE_GPD:
				switch( argType.variableType )
				{
				case VARIABLE_TYPE_GPD:
					{
						CGPReg srcReg( gpd( src ) );
						compiler->emit( INST_MOV, &dst, &srcReg );
						return;
					}
#		if ( QOR_ARCH_WORDSIZE == 64 )
				case VARIABLE_TYPE_GPQ:
				case VARIABLE_TYPE_MM:
					{
						CGPReg srcReg( gpq( src ) );
						compiler->emit( INST_MOV, &dst, &srcReg );
						return;
					}
#		endif // ASMJIT_X64
				}
			break;

#		if ( QOR_ARCH_WORDSIZE == 64 )
			case VARIABLE_TYPE_GPQ:
				switch( argType.variableType )
				{
				case VARIABLE_TYPE_GPD:
					{
						CGPReg srcReg( gpd( src ) );
						compiler->emit( INST_MOV, &dst, &srcReg );
						return;
					}
				case VARIABLE_TYPE_GPQ:
					{
						CGPReg srcReg( gpd( src ) );
						compiler->emit( INST_MOV, &dst, &srcReg );
						return;
					}
				case VARIABLE_TYPE_MM:
					{
						CGPReg srcReg( gpd( src ) );
						compiler->emit( INST_MOVQ, &dst, &srcReg );
						return;
					}
				}
			break;
#		endif // ASMJIT_X64

			case VARIABLE_TYPE_MM:
				switch( argType.variableType )
				{
				case VARIABLE_TYPE_GPD:
				case VARIABLE_TYPE_X87_1F:
				case VARIABLE_TYPE_XMM_1F:
					{
						CMMReg srcReg( mm( src ) );
						compiler->emit( INST_MOVD, &dst, &srcReg );
						return;
					}
				case VARIABLE_TYPE_GPQ:
				case VARIABLE_TYPE_MM:
				case VARIABLE_TYPE_X87_1D:
				case VARIABLE_TYPE_XMM_1D:
					{
						CMMReg srcReg( mm( src ) );
						compiler->emit( INST_MOVQ, &dst, &srcReg );
						return;
					}
				}
				break;

			// We allow incompatible types here, because the called can convert them
			// to correct format before function is called.

			case VARIABLE_TYPE_XMM:
			case VARIABLE_TYPE_XMM_4F:
			case VARIABLE_TYPE_XMM_2D:
				switch (argType.variableType)
				{
				case VARIABLE_TYPE_XMM:
					{
						CXMMReg srcReg( xmm( src ) );
						compiler->emit( INST_MOVDQU, &dst, &srcReg );
						return;
					}
				case VARIABLE_TYPE_XMM_1F:
				case VARIABLE_TYPE_XMM_4F:
					{
						CXMMReg srcReg( xmm( src ) );
						compiler->emit( INST_MOVUPS, &dst, &srcReg );
						return;
					}
				case VARIABLE_TYPE_XMM_1D:
				case VARIABLE_TYPE_XMM_2D:
					{
						CXMMReg srcReg( xmm( src ) );
						compiler->emit( INST_MOVUPD, &dst, &srcReg );
						return;
					}
				}
				break;

			case VARIABLE_TYPE_XMM_1F:
				switch( argType.variableType )
				{
				case VARIABLE_TYPE_X87_1F:
				case VARIABLE_TYPE_XMM:
				case VARIABLE_TYPE_XMM_1F:
				case VARIABLE_TYPE_XMM_4F:
				case VARIABLE_TYPE_XMM_1D:
				case VARIABLE_TYPE_XMM_2D:
					{
						CXMMReg srcReg( xmm( src ) );
						compiler->emit( INST_MOVSS, &dst, &srcReg );
						return;
					}
				}
				break;

			case VARIABLE_TYPE_XMM_1D:
				switch( argType.variableType )
				{
				case VARIABLE_TYPE_X87_1D:
				case VARIABLE_TYPE_XMM:
				case VARIABLE_TYPE_XMM_1F:
				case VARIABLE_TYPE_XMM_4F:
				case VARIABLE_TYPE_XMM_1D:
				case VARIABLE_TYPE_XMM_2D:
					{
						CXMMReg srcReg( xmm( src ) );
						compiler->emit( INST_MOVSD, &dst, &srcReg );
						return;
					}
				}
				break;
			}

			compiler->setError( ERROR_INCOMPATIBLE_ARGUMENT );
		}

		//------------------------------------------------------------------------------
		void CECall::_moveSpilledVariableToStack( Cx86HLAContext& cc, VarData* vdata, const CFunctionPrototype::Argument& argType, Cmp_unsigned__int32 temporaryGpReg, Cmp_unsigned__int32 temporaryXmmReg ) __QCMP_THROW
		{
			assert( argType.registerIndex == INVALID_VALUE );
			assert( vdata->registerIndex == INVALID_VALUE );

			Cx86HLAIntrinsics* compiler = dynamic_cast< Cx86HLAIntrinsics* >( cc.getHighLevelAssembler() );

			CMem src = cc._getVarMem( vdata );
			CMem dst = ptr( Cx86CPUCore::nsp, -(int)sizeof(Cmp_int_ptr) + argType.stackOffset );

			switch( vdata->type )
			{
			case VARIABLE_TYPE_GPD:
				switch (argType.variableType)
				{
				case VARIABLE_TYPE_GPD:
					{
						CGPReg TemporaryGPReg( gpd( temporaryGpReg ) );
						compiler->emit( INST_MOV, &TemporaryGPReg, &src );
						compiler->emit( INST_MOV, &dst, &TemporaryGPReg );
						return;
					}
#		if ( QOR_ARCH_WORDSIZE == 64 )
				case VARIABLE_TYPE_GPQ:
				case VARIABLE_TYPE_MM:
					{
						CGPReg TemporaryGPReg( gpd( temporaryGpReg ) );
						CGPReg TemporaryGQReg( gpq( temporaryGpReg ) );
						compiler->emit( INST_MOV, &TemporaryGPReg, &src );
						compiler->emit( INST_MOV, &dst, &TemporaryGQReg );
						return;
					}
#		endif// ASMJIT_X64
				}
				break;

#	if ( QOR_ARCH_WORDSIZE == 64 )
			case VARIABLE_TYPE_GPQ:
				switch( argType.variableType )
				{
				case VARIABLE_TYPE_GPD:
					{
						CGPReg TemporaryGPReg( gpd( temporaryGpReg ) );
						compiler->emit( INST_MOV, &TemporaryGPReg, &src );
						compiler->emit( INST_MOV, &dst, &TemporaryGPReg );
						return;
					}
				case VARIABLE_TYPE_GPQ:
				case VARIABLE_TYPE_MM:
					{
						CGPReg TemporaryGQReg( gpq( temporaryGpReg ) );
						compiler->emit( INST_MOV, &TemporaryGQReg, &src );
						compiler->emit( INST_MOV, &dst, &TemporaryGQReg );
						return;
					}
				}
				break;
#	endif // ASMJIT_X64

			case VARIABLE_TYPE_MM:
				switch( argType.variableType )
				{
				case VARIABLE_TYPE_GPD:
				case VARIABLE_TYPE_X87_1F:
				case VARIABLE_TYPE_XMM_1F:
					{
						CGPReg TemporaryGPReg( gpd( temporaryGpReg ) );
						compiler->emit( INST_MOV, &TemporaryGPReg, &src );
						compiler->emit( INST_MOV, &dst, &TemporaryGPReg );
						return;
					}
				case VARIABLE_TYPE_GPQ:
				case VARIABLE_TYPE_MM:
				case VARIABLE_TYPE_X87_1D:
				case VARIABLE_TYPE_XMM_1D:
					// TODO
					return;
				}
				break;

			// We allow incompatible types here, because the called can convert them
			// to correct format before function is called.

			case VARIABLE_TYPE_XMM:
			case VARIABLE_TYPE_XMM_4F:
			case VARIABLE_TYPE_XMM_2D:
				switch( argType.variableType )
				{
				case VARIABLE_TYPE_XMM:
					{
						CXMMReg TemporaryXMMReg( xmm( temporaryXmmReg ) );
						compiler->emit( INST_MOVDQU, &TemporaryXMMReg, &src );
						compiler->emit( INST_MOVDQU, &dst, &TemporaryXMMReg );
						return;
					}
				case VARIABLE_TYPE_XMM_1F:
				case VARIABLE_TYPE_XMM_4F:
					{
						CXMMReg TemporaryXMMReg( xmm( temporaryXmmReg ) );
						compiler->emit( INST_MOVUPS, &TemporaryXMMReg, &src );
						compiler->emit( INST_MOVUPS, &dst, &TemporaryXMMReg );
						return;
					}
				case VARIABLE_TYPE_XMM_1D:
				case VARIABLE_TYPE_XMM_2D:
					{
						CXMMReg TemporaryXMMReg( xmm( temporaryXmmReg ) );
						compiler->emit( INST_MOVUPD, &TemporaryXMMReg, &src );
						compiler->emit( INST_MOVUPD, &dst, &TemporaryXMMReg );
						return;
					}
				}
				break;

			case VARIABLE_TYPE_XMM_1F:
				switch( argType.variableType )
				{
				case VARIABLE_TYPE_X87_1F:
				case VARIABLE_TYPE_XMM:
				case VARIABLE_TYPE_XMM_1F:
				case VARIABLE_TYPE_XMM_4F:
				case VARIABLE_TYPE_XMM_1D:
				case VARIABLE_TYPE_XMM_2D:
					{
						CXMMReg TemporaryXMMReg( xmm( temporaryXmmReg ) );
						compiler->emit( INST_MOVSS, &TemporaryXMMReg, &src );
						compiler->emit( INST_MOVSS, &dst, &TemporaryXMMReg );
						return;
					}
				}
				break;

			case VARIABLE_TYPE_XMM_1D:
				switch( argType.variableType )
				{
				case VARIABLE_TYPE_X87_1D:
				case VARIABLE_TYPE_XMM:
				case VARIABLE_TYPE_XMM_1F:
				case VARIABLE_TYPE_XMM_4F:
				case VARIABLE_TYPE_XMM_1D:
				case VARIABLE_TYPE_XMM_2D:
					{
						CXMMReg TemporaryXMMReg( xmm( temporaryXmmReg ) );
						compiler->emit( INST_MOVSD, &TemporaryXMMReg, &src );
						compiler->emit( INST_MOVSD, &dst, &TemporaryXMMReg );
						return;
					}
				}
				break;
			}

			compiler->setError( ERROR_INCOMPATIBLE_ARGUMENT );
		}

		//------------------------------------------------------------------------------
		void CECall::_moveSrcVariableToRegister( Cx86HLAContext& cc, VarData* vdata, const CFunctionPrototype::Argument& argType ) __QCMP_THROW
		{
			Cmp_unsigned__int32 dst = argType.registerIndex;
			Cmp_unsigned__int32 src = vdata->registerIndex;

			Cx86HLAIntrinsics* compiler = dynamic_cast< Cx86HLAIntrinsics* >( cc.getHighLevelAssembler() );

			if( src != INVALID_VALUE )
			{
				switch( argType.variableType )
				{
				case VARIABLE_TYPE_GPD:
					switch (vdata->type)
					{
					case VARIABLE_TYPE_GPD:
#		if ( QOR_ARCH_WORDSIZE == 64 )
					case VARIABLE_TYPE_GPQ:
#		endif // ASMJIT_X64
						{
							CGPReg dstReg( gpd( dst ) );
							CGPReg srcReg( gpd( src ) );
							compiler->emit( INST_MOV, &dstReg, &srcReg );
							return;
						}
					case VARIABLE_TYPE_MM:
						{
							CGPReg dstReg( gpd( dst ) );
							CGPReg srcReg( gpd( src ) );
							compiler->emit( INST_MOVD, &dstReg, &srcReg );
							return;
						}
					}
					break;

#		if ( QOR_ARCH_WORDSIZE == 64 )
				case VARIABLE_TYPE_GPQ:
					switch( vdata->type )
					{
					case VARIABLE_TYPE_GPD:
						{
							CGPReg dstReg( gpd( dst ) );
							CGPReg srcReg( gpd( src ) );
							compiler->emit( INST_MOV, &dstReg, &srcReg );
							return;
						}
					case VARIABLE_TYPE_GPQ:
						{
							CGPReg dstReg( gpq( dst ) );
							CGPReg srcReg( gpq( src ) );
							compiler->emit( INST_MOV, &dstReg, &srcReg );
							return;
						}
					case VARIABLE_TYPE_MM:
						{
							CGPReg dstReg( gpq( dst ) );
							CMMReg srcReg( mm( src ) );
							compiler->emit( INST_MOVQ, &dstReg, &srcReg );
							return;
						}
					}
					break;
#		endif // ASMJIT_X64

				case VARIABLE_TYPE_MM:
					switch( vdata->type )
					{
					case VARIABLE_TYPE_GPD:
						{
							CGPReg dstReg( gpd( dst ) );
							CGPReg srcReg( gpd( src ) );
							compiler->emit( INST_MOVD, &dstReg, &srcReg );
							return;
						}
#		if ( QOR_ARCH_WORDSIZE == 64 )
					case VARIABLE_TYPE_GPQ:
						{
							CGPReg dstReg( gpd( dst ) );
							CGPReg srcReg( gpd( src ) );
							compiler->emit( INST_MOVQ, &dstReg, &srcReg );
							return;
						}
#		endif // ASMJIT_X64
					case VARIABLE_TYPE_MM:
						{
							CMMReg dstReg( mm( dst ) );
							CMMReg srcReg( mm( src ) );
							compiler->emit(INST_MOVQ, &dstReg, &srcReg );
							return;
						}
					}
					break;

				case VARIABLE_TYPE_XMM:
				case VARIABLE_TYPE_XMM_4F:
				case VARIABLE_TYPE_XMM_2D:
					switch( vdata->type )
					{
					case VARIABLE_TYPE_GPD:
						{
							CXMMReg dstReg( xmm( dst ) );
							CGPReg srcReg( gpd( src ) );
							compiler->emit( INST_MOVD, &dstReg, &srcReg );
							return;
						}
#		if ( QOR_ARCH_WORDSIZE == 64 )
					case VARIABLE_TYPE_GPQ:
						{
							CXMMReg dstReg( xmm( dst ) );
							CGPReg srcReg( gpq( src ) );
							compiler->emit( INST_MOVQ, &dstReg, &srcReg );
							return;
						}
#		endif // ASMJIT_X64
					case VARIABLE_TYPE_MM:
						{
							CXMMReg dstReg( xmm( dst ) );
							CMMReg srcReg( mm( src ) );
							compiler->emit( INST_MOVQ, &dstReg, &srcReg );
							return;
						}
					case VARIABLE_TYPE_XMM:
					case VARIABLE_TYPE_XMM_1F:
					case VARIABLE_TYPE_XMM_4F:
					case VARIABLE_TYPE_XMM_1D:
					case VARIABLE_TYPE_XMM_2D:
						{
							CXMMReg dstReg( xmm( dst ) );
							CXMMReg srcReg( xmm( src ) );
							compiler->emit( INST_MOVDQA, &dstReg, &srcReg );
							return;
						}
					}
					break;

				case VARIABLE_TYPE_XMM_1F:
					switch( vdata->type )
					{
					case VARIABLE_TYPE_MM:
						{
							CXMMReg dstReg( xmm( dst ) );
							CMMReg srcReg( mm( src ) );
							compiler->emit( INST_MOVQ, &dstReg, &srcReg );
							return;
						}
					case VARIABLE_TYPE_XMM:
						{
							CXMMReg dstReg( xmm( dst ) );
							CXMMReg srcReg( xmm( src ) );
							compiler->emit( INST_MOVDQA, &dstReg, &srcReg );
							return;
						}
					case VARIABLE_TYPE_XMM_1F:
					case VARIABLE_TYPE_XMM_4F:
						{
							CXMMReg dstReg( xmm( dst ) );
							CXMMReg srcReg( xmm( src ) );
							compiler->emit( INST_MOVSS, &dstReg, &srcReg );
							return;
						}
					case VARIABLE_TYPE_XMM_1D:
					case VARIABLE_TYPE_XMM_2D:
						{
							CXMMReg dstReg( xmm( dst ) );
							CXMMReg srcReg( xmm( src ) );
							compiler->emit( INST_CVTSD2SS, &dstReg, &srcReg );
							return;
						}
					}
					break;

				case VARIABLE_TYPE_XMM_1D:
					switch( vdata->type )
					{
					case VARIABLE_TYPE_MM:
						{
							CXMMReg dstReg( xmm( dst ) );
							CMMReg srcReg( mm( src ) );
							compiler->emit( INST_MOVQ, &dstReg, &srcReg );
							return;
						}
					case VARIABLE_TYPE_XMM:
						{
							CXMMReg dstReg( xmm( dst ) );
							CXMMReg srcReg( xmm( src ) );
							compiler->emit( INST_MOVDQA, &dstReg, &srcReg );
							return;
						}
					case VARIABLE_TYPE_XMM_1F:
					case VARIABLE_TYPE_XMM_4F:
						{
							CXMMReg dstReg( xmm( dst ) );
							CXMMReg srcReg( xmm( src ) );
							compiler->emit( INST_CVTSS2SD, &dstReg, &srcReg );
							return;
						}
					case VARIABLE_TYPE_XMM_1D:
					case VARIABLE_TYPE_XMM_2D:
						{
							CXMMReg dstReg( xmm( dst ) );
							CXMMReg srcReg( xmm( src ) );
							compiler->emit( INST_MOVSD, &dstReg, &srcReg );
							return;
						}
					}
					break;
				}
			}
			else
			{
				CMem mem = cc._getVarMem( vdata );

				switch( argType.variableType )
				{
				case VARIABLE_TYPE_GPD:
					switch (vdata->type)
					{
					case VARIABLE_TYPE_GPD:
#		if ( QOR_ARCH_WORDSIZE == 64 )
					case VARIABLE_TYPE_GPQ:
#		endif // ASMJIT_X64
						{
							CGPReg dstReg( gpd( dst ) );
							compiler->emit( INST_MOV, &dstReg, &mem );
							return;
						}
					case VARIABLE_TYPE_MM:
						{
							CGPReg dstReg( gpd( dst ) );
							compiler->emit( INST_MOVD, &dstReg, &mem );
							return;
						}
					}
					break;

#		if ( QOR_ARCH_WORDSIZE == 64 )
				case VARIABLE_TYPE_GPQ:
					switch( vdata->type )
					{
					case VARIABLE_TYPE_GPD:
						{
							CGPReg dstReg( gpd( dst ) );
							compiler->emit( INST_MOV, &dstReg, &mem );
							return;
						}
					case VARIABLE_TYPE_GPQ:
						{
							CGPReg dstReg( gpq( dst ) );
							compiler->emit( INST_MOV, &dstReg, &mem );
							return;
						}
					case VARIABLE_TYPE_MM:
						{
							CGPReg dstReg( gpq( dst ) );
							compiler->emit( INST_MOVQ, &dstReg, &mem );
							return;
						}
					}
					break;
#		endif // ASMJIT_X64

				case VARIABLE_TYPE_MM:
					switch( vdata->type )
					{
					case VARIABLE_TYPE_GPD:
						{
							CGPReg dstReg( gpd( dst ) );
							compiler->emit( INST_MOVD, &dstReg, &mem );
							return;
						}
#		if ( QOR_ARCH_WORDSIZE == 64 )
					case VARIABLE_TYPE_GPQ:
						{
							CGPReg dstReg( gpq( dst ) );
							compiler->emit( INST_MOVQ, &dstReg, &mem );
							return;
						}
#		endif // ASMJIT_X64
					case VARIABLE_TYPE_MM:
						{
							CMMReg dstReg( mm( dst ) );
							compiler->emit( INST_MOVQ, &dstReg, &mem );
							return;
						}
					}
					break;

				case VARIABLE_TYPE_XMM:
				case VARIABLE_TYPE_XMM_4F:
				case VARIABLE_TYPE_XMM_2D:
					switch( vdata->type )
					{
					case VARIABLE_TYPE_GPD:
						{
							CXMMReg dstReg( xmm( dst ) );
							compiler->emit( INST_MOVD, &dstReg, &mem );
							return;
						}
#		if ( QOR_ARCH_WORDSIZE == 64 )
					case VARIABLE_TYPE_GPQ:
						{
							CXMMReg dstReg( xmm( dst ) );
							compiler->emit( INST_MOVQ, &dstReg, &mem );
							return;
						}
#		endif // ASMJIT_X64
					case VARIABLE_TYPE_MM:
						{
							CXMMReg dstReg( xmm( dst ) );
							compiler->emit( INST_MOVQ, &dstReg, &mem );
							return;
						}
					case VARIABLE_TYPE_XMM:
					case VARIABLE_TYPE_XMM_1F:
					case VARIABLE_TYPE_XMM_4F:
					case VARIABLE_TYPE_XMM_1D:
					case VARIABLE_TYPE_XMM_2D:
						{
							CXMMReg dstReg( xmm( dst ) );
							compiler->emit( INST_MOVDQA, &dstReg, &mem );
							return;
						}
					}
					break;

				case VARIABLE_TYPE_XMM_1F:
					switch( vdata->type )
					{
					case VARIABLE_TYPE_MM:
						{
							CXMMReg dstReg( xmm( dst ) );
							compiler->emit( INST_MOVQ, &dstReg, &mem );
							return;
						}

					case VARIABLE_TYPE_XMM:
						{
							CXMMReg dstReg( xmm( dst ) );
							compiler->emit( INST_MOVDQA, &dstReg, &mem );
							return;
						}
					case VARIABLE_TYPE_XMM_1F:
					case VARIABLE_TYPE_XMM_4F:
						{
							CXMMReg dstReg( xmm( dst ) );
							compiler->emit( INST_MOVSS, &dstReg, &mem );
							return;
						}
					case VARIABLE_TYPE_XMM_1D:
					case VARIABLE_TYPE_XMM_2D:
						{
							CXMMReg dstReg( xmm( dst ) );
							compiler->emit( INST_CVTSD2SS, &dstReg, &mem );
							return;
						}
					}
					break;

				case VARIABLE_TYPE_XMM_1D:
					switch( vdata->type )
					{
					case VARIABLE_TYPE_MM:
						{
							CXMMReg dstReg( xmm( dst ) );
							compiler->emit( INST_MOVQ, &dstReg, &mem );
							return;
						}

					case VARIABLE_TYPE_XMM:
						{
							CXMMReg dstReg( xmm( dst ) );
							compiler->emit( INST_MOVDQA, &dstReg, &mem );
							return;
						}
					case VARIABLE_TYPE_XMM_1F:
					case VARIABLE_TYPE_XMM_4F:
						{
							CXMMReg dstReg( xmm( dst ) );
							compiler->emit( INST_CVTSS2SD, &dstReg, &mem );
							return;
						}
					case VARIABLE_TYPE_XMM_1D:
					case VARIABLE_TYPE_XMM_2D:
						{
							CXMMReg dstReg( xmm( dst ) );
							compiler->emit( INST_MOVSD, &dstReg, &mem );
							return;
						}
					}
					break;
				}
			}

			compiler->setError( ERROR_INCOMPATIBLE_ARGUMENT );
		}

		//------------------------------------------------------------------------------
		// Prototype & Arguments Management.
		void CECall::_setPrototype( Cmp_unsigned__int32 callingConvention, const Cmp_unsigned__int32* arguments, Cmp_unsigned__int32 argumentsCount, Cmp_unsigned__int32 returnValue ) __QCMP_THROW
		{
			m_FunctionPrototype.setPrototype( callingConvention, arguments, argumentsCount, returnValue );

			m_paArgs = new( ( dynamic_cast< Cx86HLAIntrinsics* >( getHLA() ) )->getZone().zalloc( sizeof(COperand*) * argumentsCount ) ) COperand*[argumentsCount];
			memset( m_paArgs, 0, sizeof(COperand*) * argumentsCount );
		}

		//------------------------------------------------------------------------------
		bool CECall::setArgument( Cmp_unsigned__int32 i, const COperand* pArg ) __QCMP_THROW
		{
			assert( i < m_FunctionPrototype.getArgumentsCount() );
			if( i >= m_FunctionPrototype.getArgumentsCount() )
			{
				return false;
			}
			m_paArgs[ i ] = pArg->Clone( ( dynamic_cast< Cx86HLAIntrinsics* >( getHLA() ) )->getZone() );
			return true;
		}
		/*
		//------------------------------------------------------------------------------
		bool CECall::setArgument( Cmp_unsigned__int32 i, const CBaseVar& var ) __QCMP_THROW
		{
			assert( i < m_FunctionPrototype.getArgumentsCount() );
			if( i >= m_FunctionPrototype.getArgumentsCount() )
			{
				return false;
			}
			m_paArgs[ i ] = var.Clone( ( dynamic_cast< Cx86HLAIntrinsics* >( getHLA() ) )->getZone() );
			return true;
		}

		//------------------------------------------------------------------------------
		bool CECall::setArgument( Cmp_unsigned__int32 i, const CImm& imm ) __QCMP_THROW
		{
			assert( i < m_FunctionPrototype.getArgumentsCount() );
			if( i >= m_FunctionPrototype.getArgumentsCount() )
			{
				return false;
			}
			m_paArgs[ i ] = imm.Clone( ( dynamic_cast< Cx86HLAIntrinsics* >( getHLA() ) )->getZone() );
			return true;
		}
		*/
		//------------------------------------------------------------------------------
		bool CECall::setReturn( const COperand& first, const COperand& second ) __QCMP_THROW
		{
			m_apRet[ 0 ] = first.Clone( ( dynamic_cast< Cx86HLAIntrinsics* >( getHLA() ) )->getZone() );
			m_apRet[ 1 ] = second.Clone( ( dynamic_cast< Cx86HLAIntrinsics* >( getHLA() ) )->getZone() );

			return true;
		}

	}//nsx86
}//nsArch

#endif//( QOR_ARCH == QOR_ARCH_X86_32 || QOR_ARCH == QOR_ARCH_X86_64 )
